"""
acr_sess_analys.py

This script runs analyses across sessions using a Session object with data 
generated by the Allen Institute OpenScope experiments for the Credit 
Assignment Project.

Authors: Colleen Gillon

Date: October, 2019

Note: this code uses python 3.7.

"""

import warnings

import numpy as np
import scipy.stats as scist

from util import file_util, gen_util, logger_util, math_util, rand_util
from sess_util import sess_gen_util, sess_ntuple_util, sess_str_util
from extra_analysis import quant_analys, signif_grps
from extra_plot_fcts import acr_sess_analysis_plots as acr_sess_plots


MIN_N = 2 # minimum number of values outside CIs


logger = logger_util.get_module_logger(name=__name__)


#############################################
def set_multcomp(permpar, sessions=None, n_linpla=4, n_sess=1, factor=1, 
                 CIs=True):
    """
    set_multcomp(permpar)

    Returns permpar updated with the number of comparisons computed from the 
    sessions, if permpar.multcomp is True.

    Required args:
        - permpar (PermPar) : named tuple containing permutation parameters
    
    Optional args:
        - sessions (list): nested list of Session objects 
                           (linpla x mouse x sess) used to infer 
                           n_linpla and n_sess, if provided
                           default: None
        - n_linpla (int) : number of lines/planes, used if sessions is None
                           default: 4
        - n_sess (int)   : number of sessions, used if sessions is None
                           default: 1
        - factor (int)   : additional factor by which to multiply the number of 
                           comparisons
                           default: 1
        - CIs (bool)     : whether confidence interval comparisons are included
                           default: True

    Returns:
        - permpar (PermPar): updated permutation parameter named tuple
    """

    if permpar.multcomp:
        if sessions is not None:
            n_linpla = (len(sessions))
            n_sess = [len(m_sess) for lp_sess in sessions for m_sess in lp_sess]
            if len(list(set(n_sess))) != 1:
                raise RuntimeError("There should be the same number of "
                    "sessions for each mouse.")
            n_sess = n_sess[0]

        n_comps = 0
        
        # sessions compared to their CIs
        if CIs:
            n_comps += n_sess

        # session pair comparisons
        k = 2
        if n_sess >= k:
            fact = np.math.factorial
            n_comps += fact(n_sess) / (fact(k) * fact(n_sess - k))

        # for each line/plane, and multiplied by specified factor
        n_comps *= n_linpla 
        
        # interplane comparisons (approximate if missing planes)
        n_comps += n_sess * (n_linpla // 2)

        # multiplied by specified factor
        n_comps *= factor

        permpar = sess_ntuple_util.get_modif_ntuple(
            permpar, "multcomp", int(n_comps)
            )

    return permpar
    
    
#############################################
def split_by_linpla(sessions, rem_empty=False):
    """
    split_by_linpla(sessions)

    Returns nested list of sessions organized by line/plane.

    Required args:
        - sessions (list): nested list of Session objects (mouse x sess)

    Optional args:
        - rem_empty (bool): if True, lines/planes with no sessions are omitted
                            default: False

    Returns:
        - linpla_sess (list) : nested list of Session objects 
                               (linpla x mouse x sess) (None for missing 
                               sessions)
        - linpla_order (list): line x plane order
    """

    lines   = ["L2/3", "L5"]
    planes  = ["dendrites", "soma"]
    linpla_order = [f"{lin} {pla[:4]}" for pla in planes for lin in lines]
    linpla_strip = [s.replace("/", "") for s in linpla_order]
    
    linpla_sess = [[] for _ in range(len(linpla_order))] # linpla x mice x sess
    for mouse_sess in sessions:
        line = list(set([sess.line for sess in mouse_sess if sess is not None]))
        if len(line) != 1:
            raise RuntimeError("Error - why multiple lines? (or None?)")
        else:
            line = line[0][:3].strip("-")
        
        plas = [sess.plane for sess in mouse_sess if sess is not None]
        pla_vals = list(set(plas))

        for pla in pla_vals:
            sesses = []
            for sess in mouse_sess:
                if sess is None or sess.plane != pla:
                    sesses.append(None)
                else:
                    sesses.append(sess)             
            if list(set(sesses)) != [None]: # only add if it"s not all None
                idx = linpla_strip.index(f"{line} {pla}")
                linpla_sess[idx].append(sesses)

    # check for empty lists in any lin/pla
    if rem_empty:
        rem_idx = []
        for l, sessions in enumerate(linpla_sess):
            if len(sessions) == 0:
                rem_idx.append(l)
        linpla_order = gen_util.remove_idx(linpla_order, rem_idx)
        linpla_sess = gen_util.remove_idx(linpla_sess, rem_idx)

    return linpla_sess, linpla_order


#############################################
def comp_vals_acr_planes(linpla_ord, vals, n_perms=None, normal=True, 
                         stats="mean"):
    """
    comp_vals_acr_planes(linpla_ord, vals)

    Returns p values for comparisons across planes within lines.

    Required args:
        - linpla_ord (list): ordered list of planes/lines
        - vals (list)      : values, structured as 
                             planes/lines x session 

    Optional args:
        - n_perms (int): number of permutations to do if doing a permutation 
                         test. If None, a different test is used
                         default: None
        - stats (str)  : stats to use for permutation test
                         default: "mean"
        - normal (bool): whether data is expected to be normal or not 
                         (determines whether a t-test or Mann Whitney test 
                         will be done. Ignored if n_perms is not None.)
                         default: True

    Returns:
        - p_vals (2D array): p values, structured as 
                             planes/lines x session
    """

    lines = ["L2/3", "L5"]
    n_sess = len(vals[0])
    p_vals = np.full([len(lines), n_sess], np.nan)
    for li, line in enumerate(lines):
        idx = [i for i in range(len(linpla_ord)) if line in linpla_ord[i]]
        # do comparison
        if len(idx) == 2:
            for s in range(n_sess):
                # check for nans or None
                data = [vals[i][s] for i in idx]
                
                skip = False
                for d in data:
                    if d is None or len(d) == 0:
                        skip = True
                if skip:
                    continue
                                
                if n_perms is not None:                    
                    p_vals[li, s] = rand_util.get_op_p_val(
                        data, n_perms, stats=stats, op="diff")
                elif normal:
                    p_vals[li, s] = scist.ttest_ind(
                        data[0], data[1], axis=None)[1]
                else:
                    p_vals[li, s] = scist.mannwhitneyu(data[0], data[1])[1]

    return p_vals
    

#############################################
def get_n_comps(all_p_vals, n_sess, lin_p_vals=None):
    """
    get_n_comps(all_p_vals, n_sess)

    Returns number of comparisons done for all lines and planes, as well
    as the theoretical max number of comparisons each dataset is included in.

    Required args:
        - all_p_vals (list): list of p-values, structured as 
                             line/plane x comparison
        - n_sess (int)     : number of sessions in each line/plane (incl. None)

    Optional args:
        - lin_p_vals (list): list of p-values, structured as 
                             line x comparison

    Returns:
        - tot_n_comps (int)  : total number of comparisons for all lines and 
                               planes
        - max_comps_per (int): maximum number of comparisons for each dataset 
                               (theoretical - based on number of sessions)
    """

    theor_tot = np.sum(range(n_sess)[1:])
    if theor_tot != len(all_p_vals[0]):
        raise RuntimeError("Theoretical number of comparisons within "
            f"layer/planes is expected to be {theor_tot}, but is "
            f"{len(all_p_vals[0])}.")

    p_vals = [p for all_ps in all_p_vals for p in all_ps] 
    
    if lin_p_vals is not None:
        p_vals = p_vals + [p for all_ps in lin_p_vals for p in all_ps]

    tot_n_comps = np.count_nonzero(~np.isnan(p_vals))

    # max number of comparisons each dataset is involved in
    max_comps_per = n_sess - 1 + (lin_p_vals is not None)

    return tot_n_comps, max_comps_per
    

#############################################
def data_from_refs(sess, refs, analyspar, stimpar, datatype="roi", 
                   integ=False, baseline=0.0, base_pre=None, ch_fl=None, 
                   ref_type="segs"):
    """
    data_from_refs(sess, segs, analyspar, stimpar)

    Returns data for the session.

    Required args:
        - sess (Session)       : Session object
        - refs (list)          : segments or twop frames
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - base_pre (num)        : pre value based on which to calculate 
                                  baseline. If None, stimpar.pre is used.
                                  default: None
        - ch_fl (list)          : flanks in sec [pre sec, post sec] around 
                                  frames to check for removal if out of bounds
                                  default: None
        - ref_type (str)        : type of reference provided 
                                  ("segs", "twop_frs", "stim_frs")
                                  default: "segs"

    Returns:
        - data_arr (1-3D array): data array structured as 
                                 [x ROIs] x seq [x frames]
    """

    if analyspar.rem_bad:
        nanpol = None
    else:
        nanpol = "omit"

    args = {"rem_bad": analyspar.rem_bad,
            "scale"  : analyspar.scale}

    if ref_type not in ["segs", "twop_frs", "stim_frs"]:
        gen_util.accepted_values_error(
            "ref_type", ref_type, ["segs", "twop_frs", "stim_frs"]
            )

    # retrieve stimulus type
    if stimpar.stimtype == "both": # use either
        if ref_type not in ["twop_frs", "stim_frs"]:
            raise ValueError("If stimpar.stimtype is 'both', must provide "
                "'twop_frs' or 'stim_frs' as ref_type.")
        for stimtype in ["gabors", "visflow"]:
            if hasattr(sess, stimtype):
                stim = sess.get_stim(stimtype)
                break
    else:
        stim = sess.get_stim(stimpar.stimtype)

    use_ch_fl = ch_fl
    if baseline:
        if use_ch_fl is None:
            use_ch_fl = [0, 0]
        if base_pre is None:
            base_pre = stimpar.pre
        base_pre, base_post = quant_analys.define_transition_baseline(
            stimpar.stimtype, stimpar.gabfr, baseline, base_pre, stimpar.post)
        # expand flank checking as needed
        use_ch_fl = [np.max([p, b]) 
            for p, b in zip(use_ch_fl, [base_pre, base_post])]
    if datatype == "roi":
        if ref_type == "segs":
            fr_ns = stim.get_fr_by_seg(
                refs, start=True, stop=True, ch_fl=use_ch_fl, fr_type="twop"
                )[f"start_frame_twop"]
        elif ref_type == "twop_frs":
            if ch_fl is not None:
                fr_ns = stim.sess.check_flanks(refs, ch_fl, fr_type="twop")
        else:
            raise ValueError("If 'datatype' is 'roi', must provide either "
                "'segs' or 'twop_frs' as ref_type.")
        if stim.sess.only_tracked_rois != analyspar.tracked:
            raise RuntimeError(
                "stim.sess.only_tracked_rois should match analyspar.tracked."
                )
        fct = stim.get_roi_data
        col = "roi_traces"
        args["fluor"] = analyspar.fluor
    elif datatype == "run":
        # array: 1 x sequences
        if ref_type == "segs":
            fr_ns = stim.get_fr_by_seg(
                refs, start=True, stop=True, ch_fl=use_ch_fl, fr_type="stim"
                )[f"start_frame_stim"]
        elif ref_type == "stim_frs":
            if ch_fl is not None:
                fr_ns = stim.sess.check_flanks(refs, ch_fl, fr_type="stim")
        else:
            raise ValueError("If 'datatype' is 'run', must provide either "
                "'segs' or 'stim_frs' as ref_type.")
        fct = stim.get_run_data
        col = "run_velocity"
    else:
        gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

    if len(fr_ns) == 0:
        raise RuntimeError("No frames found given flank requirements.")

    data_arr = gen_util.reshape_df_data(
        fct(fr_ns, stimpar.pre, stimpar.post, **args)[col], 
        squeeze_cols=True)

    if baseline:
        base_data = gen_util.reshape_df_data(
            fct(fr_ns, base_pre, base_post, **args), squeeze_cols=True)
        end_shape = list(base_data.shape)[:-1] + [1]
        # (ROI x) sequences x frames
        base_data = math_util.mean_med(
            base_data, stats=analyspar.stats, axis=-1, nanpol=nanpol)
        data_arr = data_arr - base_data.reshape(end_shape)
    if integ:
        data_arr = math_util.integ(
            data_arr, 1. / sess.twop_fps, axis=-1, nanpol=nanpol)
    
    return data_arr


#############################################
def get_stim_onset_offset_frames(sess, stimpar, lock="stim_onset", 
                                 frametype="twop_frs"):
    """
    get_stim_onset_offset_frames(sess, stimpar)

    Returns segment numbers for each stimulus, as well as the pre/post 
    stimulus timing information

    Required args:
        - sess (Session)   : Session object
        - stimpar (StimPar): named tuple containing stimulus parameters

    Optional args:
        - lock (str)     : how to lock the stimulus (onset or offset)
                           default: "stim_onset"
        - frametype (str): type of frames to return 

    Returns:
        - stim (Stim)      : stimulus object
        - frames (1D array): start frames
    """


    if stimpar.stimtype not in "both":
        raise NotImplementedError("Implemented for both stimulus types.")

    stim = None
    for stimtype in ["gabors", "visflow"]: # use any stimulus to retrieve data
        if hasattr(sess, stimtype):
            stim = sess.get_stim(stimtype)
            break

    fr_type = frametype.replace("_frs", "")
    if lock == "stim_onset":
        frames = sess.grayscr.get_stop_fr(fr_type=fr_type)[
            f"stop_frame_{fr_type}"][:-1]
    elif lock == "stim_offset":
        frames = sess.grayscr.get_start_fr(fr_type=fr_type)[
            f"start_frame_{fr_type}"][1:]

    return stim, frames


#############################################
def get_common_oris(stimpar, split="by_exp"):
    """
    get_common_oris(stimpar)

    Returns Gabor orientations for common orientations, and checks parameters. 

    Required args:
        - stimpar (StimPar): 
            named tuple containing stimulus parameters

    Optional args:
        - split (str): 
            how to split data:
            "by_exp" (all exp, all unexp)
            default: "by_exp"

    Returns:
        - gab_oris (list): Gabor orientations common to U frames
    """

    if split != "by_exp":
        raise NotImplementedError("'common_oris' only implemented "
            "with 'split' set to 'by_exp'.")
    if stimpar.stimtype != "gabors":
        raise ValueError(
            "Index analysis with common orientations can only be run on Gabors."
            )

    gab_oris = sess_gen_util.gab_oris_common_U(stimpar.gab_ori)

    return gab_oris


#############################################
def get_seg_info(sess, stimpar, split="by_exp", prog_pos=0, common_oris=False):
    """
    get_seg_info(sess, stimpar)

    Returns segment information for a specific split type.

    Required args:
        - sess (Session)   : Session object
        - stimpar (StimPar): named tuple containing stimulus parameters

    Optional args:
        - split (str)       : how to split data, either 
                              "by_exp": all exp vs all unexp, or
                              "unexp_lock": unexp, vs preceeding exp, or
                              "exp_lock": exp, vs preceeding unexp
                              "prog_unexp": unexp, vs preceeding exp, but not
                                 locked (e.g., U, vs prev D) 
                                 (i.e., pre not necessarily equal to post)
                              "prog_exp": exp, vs preceeding unexp, but not 
                                  locked (e.g., D, vs prev U)
                                  (i.e., pre not necessarily equal to post)
                              default: "by_exp"
        - prog_pos (int)    : unexpected or expected position to retrieve if 
                              split is "prog_unexp" or "prog_exp"
                              default: 0
        - common_oris (bool): if True, only Gabor stimulus orientations shared 
                              by D and U frames are included 
                              ("by_exp" split only)
                              default: False
    
    Returns:
        - segs (list)     : segment array for each split
        - pre_posts (list): [pre, post] values for each split
    """
    
    locks = ["exp_lock", "unexp_lock"] 
    progs = ["prog_exp", "prog_unexp"]

    split_values = (["by_exp"] + locks + progs)

    if split not in split_values:
        if split in ["stim_onset", "stim_offset"]:
            raise NotImplementedError(
                "Cannot retrieve segments for stim_onset/stim_offset."
                )
        else:
            gen_util.accepted_values_error("split", split, split_values)

    
    stim = sess.get_stim(stimpar.stimtype)

    # check parameters
    if split in locks and stimpar.pre != stimpar.post:
        raise ValueError("stimpar.pre must equal stimpar.post for "
            "locked analyses.")

    if common_oris:
        gab_ori = get_common_oris(stimpar, split)
    else:
        gab_ori = stimpar.gab_ori

    # identify info for retrieving segments
    if split == "by_exp":
        gab_oris = [gab_ori, gab_ori]
        if stimpar.stimtype == "gabors":
            # if single Gabor orientation value, adjust by shifting orientation for unexp
            if stimpar.gabfr in [3, 4] and isinstance(gab_ori, int):
                gab_oris[1] = sess_gen_util.get_unexp_gab_ori(gab_ori)

            # check if unexpected component is included
            if (stimpar.gabfr * 0.3 + stimpar.post) < 0.9:
                raise RuntimeError(f"{stimpar.post}s after gaborframe "
                    f"{stimpar.gabfr} is too short to include unexpected period.")

        segs = [stim.get_segs_by_criteria(
            gabfr=stimpar.gabfr, gabk=stimpar.gabk, gab_ori=gab_oris[unexp],
            visflow_dir=stimpar.visflow_dir, visflow_size=stimpar.visflow_size, 
            unexp=unexp, 
            by="seg") for unexp in [0, 1]]
        pre_posts = [[stimpar.pre, stimpar.post]] * 2
    
    else:
        if split in locks:
            remconsec = True
            gabfr = "any"
        elif split in progs:
            remconsec = False
            gabfr = stimpar.gabfr
        
        unexp = 1 if ("unexp" in split) else 0
        segs = stim.get_segs_by_criteria(gabfr=gabfr, gabk=stimpar.gabk, 
            gab_ori=stimpar.gab_ori, visflow_dir=stimpar.visflow_dir, 
            visflow_size=stimpar.visflow_size, unexp=unexp, by="seg", 
            remconsec=remconsec)
    
        if split in locks:
            # shift to correct gabor frame
            if (stimpar.stimtype == "gabors" and 
                stimpar.gabfr not in ["any", "all"]):
                segs = [seg + stimpar.gabfr for seg in segs]
            segs = [segs] * 2
            pre_posts = [[stimpar.pre, 0], [0, stimpar.post]]
        
        elif split in progs:
            if not int(prog_pos) == float(prog_pos):
                raise ValueError("prog_pos must be of type int.")
            prog_pos = int(prog_pos)
            # get the shift values for the main and previous segments
            base_shift = 4 if stimpar.stimtype == "gabors" else 1 
            if stimpar.stimtype == "gabors" and gabfr in ["any", "all"]:
                raise NotImplementedError("Setting 'stimpar.gabfr' to "
                    "'any' or 'all' has not been sufficiently tested for "
                    "'prog' split values.")

            main_seg_shift = base_shift * prog_pos

            # get the main segment numbers            
            start_segs, n_consec = gen_util.consec(segs, smallest=True)
            if prog_pos == 0:
                main_segs = np.asarray(start_segs)
            else:
                keep_segs_idx = np.where(np.asarray(n_consec) > prog_pos)[0]
                main_segs = np.asarray(start_segs)[keep_segs_idx] + \
                    main_seg_shift

            prev_seg_shift = base_shift * (1 + prog_pos)
            main_segs = np.asarray(
                list(filter(lambda i : i >= prev_seg_shift, main_segs))
                ).reshape(-1)

            if len(main_segs) == 0:
                raise RuntimeError("No segments meet the criteria for "
                    f"'prog_pos' = {prog_pos}.")
            
            # [prev_segs, main_segs]
            segs = [main_segs - prev_seg_shift, main_segs]
            pre_posts = [[stimpar.pre, stimpar.post]] * 2

    return segs, pre_posts


#############################################
def split_data_by_sess(sess, analyspar, stimpar, datatype="roi", 
                       split="by_exp", integ=False, baseline=0.0, prog_pos=0, 
                       common_oris=False):
    """
    split_data_by_sess(sess, analyspar, stimpar)

    Returns data for the session, split as requested.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  "prog_unexp": unexp, vs preceeding exp, but
                                      not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, but not 
                                      locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  "stim_onset": grayscreen vs stimulus onset
                                  "stim_offset": stimulus offset vs grayscreen
                                  default: "by_exp"
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - prog_pos (int)        : unexpected or expected position to retrieve 
                                  if split is "prog_unexp" or "prog_exp"
                                  default: 0
        - common_oris (bool)    : if True, only Gabor stimulus orientations 
                                  common to D and U frames are included 
                                  ("by_exp" split only)
                                  default: False

    Returns:
        - data_arr (list): list of data arrays structured as 
                           split1, 2 [x ROIs] x seq [x frames]
                           
                           split1, 2 ordered in time, i.e.
                           if split in ["by_exp", "unexp_lock", "prog_unexp"]:
                               split1, 2: exp, unexp
                           elif split in ["exp_lock", "prog_exp"]:
                               split1, 2: unexp, exp
                           elif split is "stim_onset":
                               split1, 2: grayscr, stim
                           elif split is "stim_offset:
                               split1, 2: stim, grayscr
    """
    
    locks = ["exp_lock", "unexp_lock"]
    progs = ["prog_exp", "prog_unexp"]
    stim_on_offset = ["stim_onset", "stim_offset"]

    if split in (["by_exp"] + locks + progs):
        stim = sess.get_stim(stimpar.stimtype)
        refs, pre_posts = get_seg_info(
            sess, stimpar, split=split, prog_pos=prog_pos, 
            common_oris=common_oris
            )
        ref_type = "segs"
    
    elif split in stim_on_offset:
        pre_posts = [[stimpar.pre, 0], [0, stimpar.post]]
        ref_type = "twop_frs" if datatype == "roi" else "stim_frs"
        stim, frames = get_stim_onset_offset_frames(
            sess, stimpar, lock=split, frametype=ref_type
            )
        refs = [frames, frames]
        
    if split in progs:
        prev_seg_shift = np.unique(refs[1] - refs[0])
        if len(prev_seg_shift) != 1:
            raise RuntimeError(
                "Expected both sets of segs to be equally spaced."
                )
        prev_seg_shift = prev_seg_shift[0]

    data_arr = []
    for s, (subrefs, [pre, post]) in enumerate(zip(refs, pre_posts)):
        ch_fl = None
        base_pre = None
        # check flanks and baseline pre adjusted as pre and post are split up!
        if split in (locks + stim_on_offset):  
            base_pre = stimpar.pre          
            ch_fl = [stimpar.pre, stimpar.post]
        elif split in progs:
            base_pre = stimpar.pre
            
            sec_between = prev_seg_shift * stim.seg_len_s
            if stimpar.stimtype == "gabors":
                n_grayscr_segs = (3 - stimpar.gabfr + prev_seg_shift) // 4
                sec_between += n_grayscr_segs * stim.seg_len_s
            if s == 0: # for prev segs
                ch_fl = [stimpar.pre, stimpar.post + sec_between] 
            elif s == 1: # for main segs
                ch_fl = [stimpar.pre + sec_between, stimpar.post]

        stimpar_use = sess_ntuple_util.get_modif_ntuple(
            stimpar, ["pre", "post"], [pre, post])

        data_arr.append(data_from_refs(
            sess, subrefs, analyspar, stimpar_use, datatype, integ=integ, 
            baseline=baseline, base_pre=base_pre, ch_fl=ch_fl, 
            ref_type=ref_type))


        # very few stim onset/offset sequences, so best to retain all
        axis = -1 if integ else -2
        if ((split in stim_on_offset) and 
            (data_arr[s].shape[axis] != len(subrefs))):
            raise RuntimeError("Not all sequences could be retained for "
                f"{split} with stimpar.pre={stimpar.pre} and "
                f"stimpar.post={stimpar.post}.")


    return data_arr


#############################################
def dir_data_by_sess(sess, analyspar, stimpar, datatype="roi", integ=False, 
                     baseline=0.0, unexp="any", remconsec=False):
    """
    dir_data_by_sess(sess, analyspar, stimpar)

    Returns data for the session, split by direction.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - integ (bool)          : if True, sequence data is integrated
                                  default: False
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - unexp (str or int)     : unexpected value, e.g. "any", 0, 1
                                  default: "any"
        - remconsec (bool)      : if True, consecutive segments are removed
                                  default: False

    Returns:
        - data_arr (list): list of data arrays structured as 
                           nasal, temp [x ROIs] x seq [x frames]
    """

    if stimpar.stimtype != "visflow":
        raise ValueError("Cannot get direction data for Gabors.")

    if not remconsec and not (baseline is None or baseline == 0):
        raise NotImplementedError("Baseline not implemented for " 
            "Visflow direction without 'remconsec'.")

    stim = sess.get_stim(stimpar.stimtype)
    data_arr = []
    for direc in ["nasal", "temp"]:
        stimpar_sp = sess_ntuple_util.get_modif_ntuple(
            stimpar, "visflow_dir", direc)
        segs = stim.get_segs_by_criteria(
            gabfr=stimpar_sp.gabfr, gabk=stimpar_sp.gabk, 
            gab_ori=stimpar_sp.gab_ori, visflow_dir=stimpar_sp.visflow_dir, 
            visflow_size=stimpar_sp.visflow_size, remconsec=remconsec, 
            unexp=unexp, by="seg")
        data_arr.append(data_from_refs(
            sess, segs, analyspar, stimpar, datatype, integ=integ, 
            baseline=baseline, base_pre=stimpar.pre))

    return data_arr


#############################################
def split_diff_by_sess(sess, analyspar, stimpar, n_perms=1000, datatype="roi", 
                       split="by_exp", baseline=0.0):
    """
    split_diff_by_sess(sess, analyspar, stimpar)
    
    Returns session statistics for difference between sequence splits as well 
    as random values obtained from permutations.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation. If 
                                  None, random data is not calculated.
                                  default: 1000
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  "prog_unexp": unexp, vs preceeding exp, but
                                      not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, but not 
                                      locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  "stim_onset": grayscreen vs stimulus onset
                                  "stim_offset": stimulus offset vs grayscreen
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0

    Returns:
        - diff_st (1D array) : session statistics for difference between 
                               split2 and split1 sequence areas (me, err)
        - all_rand (1D array): random value obtained for each permutation 
                               (None, if n_perms is None)
        - data_arr (list)    : list of data arrays, structured as 
                               split1, 2 [x ROIs] x seq
                                                              
                               split1, 2 ordered in time, i.e.
                               if split in ["by_exp", "unexp_lock", 
                                  "prog_unexp"]:
                                   split1, 2: exp, unexp
                               elif split in ["exp_lock", "prog_exp"]:
                                   split1, 2: unexp, exp
                               elif split is "stim_onset":
                                   split1, 2: grayscr, stim
                               elif split is "stim_offset:
                                   split1, 2: stim, grayscr
    """

    nanpol = "omit"
    if analyspar.rem_bad:
        nanpol = None

    data_arr = split_data_by_sess(sess, analyspar, stimpar, datatype=datatype, 
        split=split, integ=True, baseline=baseline)

    # take mean/median across sequences
    mean_meds = [math_util.mean_med(data, stats=analyspar.stats, axis=-1, 
        nanpol=nanpol) for data in data_arr]

    last_dim = np.sum([sub.shape[-1] for sub in data_arr])
    if datatype != "roi":
        mean_meds = np.asarray(mean_meds).reshape(2, 1)
        targ = (1, last_dim)
    else:
        targ = (-1, last_dim)
    
    diff_st = math_util.get_stats(mean_meds[1] - mean_meds[0], 
        stats=analyspar.stats, error=analyspar.error, nanpol=nanpol)

    # get CI
    div = data_arr[0].shape[-1] # length of exp
    
    all_rand = None
    if n_perms is not None:
        all_rand = math_util.mean_med(rand_util.permute_diff_ratio(
            np.concatenate(data_arr, axis=-1).reshape(targ), div=div, 
            n_perms=n_perms, stats=analyspar.stats, nanpol=nanpol, op="diff"), 
            stats=analyspar.stats, axis=0, nanpol=nanpol)

    return diff_st, all_rand, data_arr


#############################################
def prog_by_sess(sess, analyspar, stimpar, datatype="roi", unexp="prog_unexp", 
                 position=0, baseline=0):
    """
    prog_by_sess(sess, analyspar, stimpar)
    
    Returns differences between unexpected sequences and preceeding expected 
    sequences across a session, as well as the average for the session.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - unexp (str)            : how to split unexpected vs exp data, either 
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., prog U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  default: "prog_unexp"
        - position (int)        : unexpected or expected position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline 
                                  default: 0

    Returns:
        - data_arr (2 or 3D array): array of data for unexpected sequences and 
                                    the preceeding expected sequence  
                                    (exp, unexp), or v.v. if unexp is 
                                    "prog_exp", structured as 
                                    (exp, unexp) [x ROIs] x seq
    """

    if unexp not in ["prog_unexp", "prog_exp"]:
        gen_util.accepted_values_error(
            "unexp", unexp, ["prog_unexp", "prog_exp"]
            )

    data_arr = split_data_by_sess(sess, analyspar, stimpar, datatype=datatype, 
        split=unexp, integ=True, baseline=baseline, 
        prog_pos=position)

    data_arr = np.asarray(data_arr)

    return data_arr


#############################################
def stim_idx_by_sess(sess, analyspar, stimpar, n_perms=1000, datatype="roi", 
                     feature="by_exp", position=0, op="d-prime", baseline=0.0, 
                     common_oris=False, seed=None, run_random=True):
    """
    stim_idx_by_sess(sess, analyspar, stimpar)
    
    Returns session item (ROIs or 1 for running) indices for difference between 
    sequences split by the specified feature, as well as their percentiles 
    based on random permutations for each item.

    Required args:
        - sess (Session)       : Session object
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split stimuli, e.g.,
                                  "by_exp": all exp vs all unexp, or
                                  "prog_unexp": first unexp, vs prec. exp, or
                                  "prog_exp": first exp, vs prec. unexp, or
                                  "dir": left v right direction
                                  default: "by_exp"
        - position (int)        : unexpected or expected position to retrieve 
                                  if feature is "prog_unexp" or "prog_exp"
                                  default: 0
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - common_oris (bool)    : if True, only Gabor stimulus orientations 
                                  common to D and U frames are included 
                                  ("by_exp" feature only)
                                  default: False
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - run_random (bool)     : if True, randomization is run and results are 
                                  returns (item_percs, all_rand)
                                  default: True

    Returns:
        - item_idxs (1D array) : item (ROIs or 1 for running) indices for the 
                                 session
        if run_random:
        - item_percs (1D array): item (ROIs or 1 for running) index 
                                 percentiles for the session, based on 
                                 each item's random permutations
        - all_rand (2D array)  : item (ROIs or 1 for running) indices 
                                 calculated through randomized permutation, 
                                    structured as item x n_perms
    """

    seed = rand_util.seed_all(seed, "cpu", log_seed=False)

    nanpol = "omit"
    if analyspar.rem_bad:
        nanpol = None

    if "dir" in feature:
        if feature == "dir_exp":
            unexp = 0
        elif feature == "dir_unexp":
            unexp = 1
        elif feature == "dir":
            unexp = "any"
        else:
            raise ValueError("If 'dir' in 'feature', must be "
                "among 'dir_exp', 'dir_unexp' or 'dir'.")

        if common_oris:
            raise ValueError("'common_oris' only applies to Gabor analyses.")

        data_arr = dir_data_by_sess(sess, analyspar, stimpar, 
            datatype=datatype, integ=True, baseline=baseline, unexp=unexp, 
            remconsec=False)
    else:
        data_arr = split_data_by_sess(sess, analyspar, stimpar, 
            datatype=datatype, split=feature, integ=True, baseline=baseline, 
            prog_pos=position, common_oris=common_oris)
    
    if op != "d-prime":
        # take statistic across sequences
        seq_mes = np.stack([math_util.mean_med(
            arr, stats=analyspar.stats, axis=-1, nanpol=nanpol) 
            for arr in data_arr])
        axis = None
    else:
        seq_mes = data_arr
        axis = -1

    # take relative difference (index)
    item_idxs = math_util.calc_op(seq_mes, op=op, nanpol=nanpol, axis=axis)

    if run_random:
        last_dim = np.sum([sub.shape[-1] for sub in data_arr])
        if datatype != "roi":
            item_idxs = np.asarray(item_idxs).reshape(-1)
            targ = (1, last_dim)
        else:
            targ = (-1, last_dim)

        # get CI
        div = data_arr[0].shape[-1] # length of exp
        # perms (items x perms)
        all_rand = rand_util.permute_diff_ratio(
            np.concatenate(data_arr, axis=-1).reshape(targ), div=div, 
            n_perms=n_perms, stats=analyspar.stats, nanpol=nanpol, op=op)

        item_percs = np.empty(len(item_idxs))
        for r, (item_idx, item_rand) in enumerate(zip(item_idxs, all_rand)):
            item_percs[r] = scist.percentileofscore(
                item_rand, item_idx, kind="mean")
        
        return item_idxs, item_percs, all_rand

    else:
        return item_idxs


#############################################
def stim_idx_acr_sesses(sessions, analyspar, stimpar, n_perms=1000, 
                        datatype="roi", feature="by_exp", position=0, 
                        op="d-prime", baseline=0.0, common_oris=False, 
                        seed=None, parallel=False):
    """
    stim_idx_acr_sesses(sessions, analyspar, stimpar)
    
    Returns item (ROIs or running) indices for difference between 
    stimulus features (e.g., unexpected v expected, visual flow direction), as 
    well as their percentiles based on random permutations for each item, 
    grouped across mice for the session number.

    Required args:
        - sessions (list)      : Session objects for each mouse
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split stimuli, e.g.,
                                  "by_exp": all exp vs all unexp, or
                                  "prog_unexp": first unexp, vs prec. exp, or
                                  "prog_exp": first exp, vs prec. unexp, or
                                  "dir_exp": left v right direction (exp.),
                                  "dir_unexp": left v right direction (unexp.),
                                  "dir": left v right direction
                                  default: "by_exp"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0 
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - common_oris (bool)    : if True, only Gabor stimulus orientations 
                                  common to D and U frames are included 
                                  ("by_exp" feature only)
                                  default: False
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, sessions are analysed in parallel 
                                  (not implemented)
                                  default: False

    Returns:
        - all_item_idxs (list) : item (ROIs or running) indices grouped across 
                                 all sessions
        - all_item_percs (list): item (ROIs or running) index percentiles, 
                                 based on each item's random permutations, 
                                 grouped across all sessions
        - all_rand_idxs (list) : for each session number, random item 
                                 (ROIs or running) indices, based on each 
                                 item's random permutations, grouped across 
                                 all sessions and items (items * n_perms)
    """

    all_item_idxs, all_item_percs, all_rand_idxs = [], [], []
    for sess in sessions:
        if sess is None:
            continue
        try:
            item_idxs, item_percs, rand_idxs = stim_idx_by_sess(
                sess, analyspar, stimpar, n_perms, datatype, feature, 
                position, op, baseline, common_oris, seed)
        except Exception as e:
            if "dir" in feature and "No segments" in str(e):
                continue
            else:
                raise e
        all_item_idxs.extend(item_idxs.tolist())
        all_item_percs.extend(item_percs.tolist())
        all_rand_idxs.extend(rand_idxs.tolist())

    return all_item_idxs, all_item_percs, all_rand_idxs


#############################################
def stim_idx_by_sesses(sessions, analyspar, stimpar, n_perms=1000, p_val=0.05, 
                       datatype="roi", feature="by_exp", op="d-prime", 
                       position=0, baseline=0.0, common_oris=False, seed=None, 
                       parallel=False):
    """
    stim_idx_by_sesses(sessions, analyspar, stimpar)
    
    Returns item (ROIs or running) indices for difference between 
    stimulus features (e.g., unexpected v expected, visual flow direction), as 
    well as their percentiles based on random permutations for each item, 
    grouped across mice for each session number.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - p_val (float)         : p-value (used to decide number of bins)
                                  default: 0.05
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split stimuli, e.g.,
                                  "by_exp": all exp vs all unexp, or
                                  "prog_unexp": first unexp, vs prec. exp, or
                                  "prog_exp": first exp, vs prece. unexp, or
                                  "dir_exp": left v right direction (exp.),
                                  "dir_unexp": left v right direction (unexp.),
                                  "dir": left v right direction
                                  default: "by_exp"
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - common_oris (bool)    : if True, only Gabor stimulus orientations 
                                  common to D and U frames are included 
                                  ("by_exp" feature only)
                                  default: False
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, sessions are analysed in parallel 
                                  default: False
    
    Returns:
        - all_item_idxs (list) : for each session number, item (ROIs or running) 
                                 index bin counts grouped across mice
        - all_item_percs (list): for each session number, item (ROIs or running) 
                                 index percentile bin counts, based on 
                                 each item's random permutations, grouped 
                                 across mice
        - all_rand_idxs (list) : for each session number, binned random item 
                                 (ROIs or running) index bin counts, 
                                 based on each item's random permutations, 
                                 grouped across mice, structured as 
                                    session (item * n_perms)
        - all_perc_pos (list)  : for each session number, percent ROIs with 
                                 positive indices, grouped across mice, 
        - sess_edges (list)    : for each session number, bin edges used for 
                                 indices, 
                                    session x [min, max]
        - sess_info (list)     : nested list of dictionaries for each 
                                 session number containing information from 
                                 each mouse, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    if len(sessions) == 0:
        raise ValueError("At least one session must be passed.") 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise RuntimeError("There should be the same number of sessions for "
            "each mouse.")
    sessions_zipped = zip(*sessions)

    n_bins = 4 / p_val
    if n_bins != int(n_bins):
        raise NotImplementedError(f"Analysis not well adapted to binning "
            f"with p-value of {p_val}.")
    else:
        n_bins = int(n_bins)

    all_item_idxs, all_item_percs, all_rand_idxs, all_poses = [], [], [], []
    sess_edges = []
    sess_info = []
    for sesses in sessions_zipped:
        sesses = list(sesses)
        all_items, all_percs, all_rand = stim_idx_acr_sesses(
            sesses, analyspar, stimpar, n_perms, datatype, 
            feature, position, op, baseline, common_oris, seed, parallel)
            
        sess_info.append(sess_gen_util.get_sess_info(
            sesses, analyspar.fluor, add_none=True, 
            incl_roi=(datatype=="roi"), rem_bad=analyspar.rem_bad))
        
        if len(all_rand) == 0:
            use_bounds = [-0.5, 0.5]
            bin_edges = np.linspace(*use_bounds, n_bins + 1)
            all_item_idxs.append(
                np.histogram(all_items, bins=bin_edges)[0].tolist())
            all_rand_idxs.append(
                (np.histogram(all_rand, bins=bin_edges)[0]).tolist())
            sess_edges.append([np.min(bin_edges), np.max(bin_edges)])
            all_item_percs.append(
                np.histogram(
                    all_percs, bins=n_bins, range=[0, 100])[0].tolist())
            all_poses.append(np.nan)
            continue
        
        # get edges for histogram 
        all_rand = np.concatenate(all_rand, axis=0)
        div = len(all_rand)/float(len(all_items))

        if op in ["diff", "d-prime"]:
            use_bounds = [np.min(all_rand), np.max(all_rand)]
        elif op == "rel_diff":
            # use extrema or outlier bounds, whichever are tighter
            rand_outlier_bounds = math_util.outlier_bounds(
                all_rand, fences="outer")
            use_bounds = [fct([o, fct(all_rand)]) for o, fct in 
                zip(rand_outlier_bounds, [np.max, np.min])]
                
        # ensure that real data is fully included
        use_bounds = [fct([fct(all_items), r]) 
            for r, fct in zip(use_bounds, [np.min, np.max])]

        n_out = np.sum(all_rand < use_bounds[0]) + \
            np.sum(all_rand > use_bounds[1])
        if n_out > 0:
            logger.warning(f"{n_out}/{len(all_rand)} random values lie "
                "outside histogram bin bounds (outliers).")

        bin_edges = np.linspace(*use_bounds, n_bins + 1)
        
        perc_pos = (len(np.where(np.asarray(all_items) > 0)[0]) * 100 / 
            len(all_items))

        all_item_idxs.append(
            np.histogram(all_items, bins=bin_edges)[0].tolist())
        all_rand_idxs.append(
            (np.histogram(all_rand, bins=bin_edges)[0]/div).tolist())
        all_item_percs.append(
            np.histogram(all_percs, bins=n_bins, range=[0, 100])[0].tolist())
        all_poses.append(perc_pos)
        sess_edges.append([np.min(bin_edges), np.max(bin_edges)])

    return [all_item_idxs, all_item_percs, all_rand_idxs, all_poses, 
        sess_edges, sess_info]


#############################################
def get_grped_roi_stats(all_roi_vals, analyspar, permpar):
    """
    get_grped_roi_stats(all_roi_vals, analyspar, permpar)

    Returns difference between sequence data for each split, with ROIs grouped 
    across mice.

    Required args:
        - all_roi_vals (list)  : sequence areas, split across groups 
                                 (e.g., exp, unexp) values for each session, 
                                 structured as
                                    session x mice x splits x ROI x seqs
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  

    Returns:
        - all_diff_st (list) : difference stats (split2 - split1) across ROIs 
                               (grouped across mice), structured as 
                                    session x stats
        - CI_vals (list)     : CIs values across ROIs, structured as 
                               session x perc (med, lo, high)
        - sign_sess (list)   : significant session indices, optionally 
                               structured by tail
        - all_diffs (list)   : differences, structured as session x ROI
        - p_vals_grped (list): p values for each comparison, organized by 
                               session pairs (where the second session is 
                               cycled in the inner loop, e.g., 0-1, 0-2, 1-2, 
                               including empty groups)
        - p_vals_sess (list) : p values for each session
    """

    # integrate multiple comparisons into p-value
    if permpar.multcomp:
        permpar = sess_ntuple_util.get_modif_ntuple(
            permpar, ["multcomp", "p_val"], 
            [False, permpar.p_val / permpar.multcomp]
            )

    # join ROIs across mice
    percs = [50.0] + math_util.get_percentiles(
        CI = (1.0 - permpar.p_val), tails=permpar.tails
        )[0]
    st_len = 2 + (analyspar.stats == "median" and analyspar.error == "std")

    nanpol = "omit"
    if analyspar.rem_bad:
        nanpol = None

    n_sess = len(all_roi_vals)
    all_diff_st = np.empty([n_sess, st_len]) * np.nan
    all_rand = np.empty([n_sess, permpar.n_perms]) * np.nan
    all_diffs = []
    for s, sess_roi_vals in enumerate(all_roi_vals):
        # mice x splits x ROIs x seqs
        sess_mean_meds = []
        sess_rands = []
        for mouse_vals in sess_roi_vals: # for each mouse
            sess_mean_meds.append([math_util.mean_med(split_vals, axis=-1, 
                stats=analyspar.stats) for split_vals in mouse_vals])
            # get CI
            div = mouse_vals[0].shape[-1] # length of exp
            # perms
            sess_rands.append(rand_util.permute_diff_ratio(
                np.concatenate(mouse_vals, axis=1), div=div, 
                n_perms=permpar.n_perms, stats=analyspar.stats, 
                nanpol=nanpol, op="diff"))

        if len(sess_mean_meds) == 0:
            all_diffs.append(None)
            continue

        # take mean/median across sequences, then diff between splits
        sess_mean_med_diffs = np.subtract(
            *np.concatenate(sess_mean_meds, axis=1)) * -1
        # take stats across ROIs
        all_diff_st[s] = math_util.get_stats(sess_mean_med_diffs, 
            stats=analyspar.stats, error=analyspar.error, nanpol=nanpol)
        # sess_rands: mouse x ROI x perm
        all_rand[s] = math_util.mean_med(
            np.concatenate(sess_rands, axis=0), axis=0, stats=analyspar.stats)
        all_diffs.append(sess_mean_med_diffs.tolist())

    # get p-values for comparisons between sessions
    p_vals_grped = rand_util.comp_vals_acr_groups(all_diffs, permpar.n_perms, 
        stats=analyspar.stats).tolist()
    
    # get CI (sess x percs)
    CI_vals = np.asarray(
        [np.percentile(all_rand, p, axis=-1) for p in percs]).T.tolist()

    # get significant session numbers (optionally by tails)
    sign_sess, p_vals_sess = rand_util.id_elem(all_rand, all_diff_st[:, 0], 
        tails=permpar.tails, p_val=permpar.p_val, min_n=MIN_N, nanpol="omit", 
        ret_pval=True)

    return [all_diff_st.tolist(), CI_vals, sign_sess, all_diffs, p_vals_grped, 
        p_vals_sess]


#############################################
def get_mouse_stats(mouse_diff_st, all_rand, analyspar, permpar):
    """
    get_mouse_stats(mouse_diff_st, all_rand, analyspar, permpar)

    Returns difference between sequence data splits across mice.

    Required args:
        - mouse_diff_st (3D array): difference statistics across ROIs or seqs, 
                                    structured as mouse x session x stats
        - all_rand (1D array)     : random values obtained for each permutation, 
                                    structured as mouse x session x perm
        - analyspar (AnalysPar)   : named tuple containing analysis parameters
        - permpar (PermPar)       : named tuple containing permutation 
                                    parameters  

    Returns:
        - all_diff_st (list): difference stats across mice, structured as 
                              session x stats
        - CI_vals (list)    : CIs values, structured as 
                              session x perc (med, lo, high)
        - sign_sess (list)  : significant session indices, optionally 
                              structured by tail
        - p_vals_sess (list): p-values for each session
    """

    # integrate multiple comparisons into p-value
    if permpar.multcomp:
        permpar = sess_ntuple_util.get_modif_ntuple(
            permpar, ["multcomp", "p_val"], 
            [False, permpar.p_val / permpar.multcomp]
            )

    # take stats across mice
    percs = [50.0] + math_util.get_percentiles(
        CI = (1.0 - permpar.p_val), tails=permpar.tails
        )[0]

    # sess x stats
    all_diff_st = math_util.get_stats(mouse_diff_st[:, :, 0], 
        stats=analyspar.stats, error=analyspar.error, axes=0, nanpol="omit").T

    # take mean/median across mice (sess x perms)
    all_rand = math_util.mean_med(
        all_rand, stats=analyspar.stats, axis=0, nanpol="omit")
    
    # get CI (sess x percs)
    CI_vals = np.asarray(
        [np.percentile(all_rand, p, axis=-1) for p in percs]).T.tolist()

    # get significant session numbers (optionally by tails)
    sign_sess, p_vals_sess = rand_util.id_elem(
        all_rand, all_diff_st[:, 0], tails=permpar.tails, p_val=permpar.p_val, 
        min_n=MIN_N, nanpol="omit", ret_pval=True)
    
    return all_diff_st.tolist(), CI_vals, sign_sess, p_vals_sess


#############################################
def split_diff_by_sesses(sessions, analyspar, stimpar, permpar, datatype="roi", 
                         split="by_exp", baseline=0.0, grped_only=False, 
                         seed=None):
    """
    split_diff_by_sesses(sessions, analyspar, stimpar, permpar)

    Returns dictionary containing difference between sequence data splits, as 
    well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  "stim_onset": grayscreen vs stimulus onset
                                  "stim_offset": stimulus offset vs grayscreen
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - grped_only (bool)     : if True, only grouped data is returned 
                                  (applied to datatype = "roi" only)
                                  default: False
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None

    Returns:
        if not grped_only:
        - mouse_diff_st (list)   : difference statistics across ROIs or seqs, 
                                   structured as mouse x session x stats
        - all_diff_st (list)     : difference stats across mice, 
                                   structured as session x stats
        - CI_vals (list)         : CIs values, structured as 
                                   session x perc (med, lo, high)
        - sign_sess (list)       : significant session indices, optionally
                                   structured by tail
        - p_vals_sess (list)     : p values for each session

        if datatype == "roi": (
        - all_diff_st_grped (list) : difference stats across ROIs (grouped 
                                        across mice), structured as 
                                        session x stats
        - CI_vals_grped (list)     : CIs values across ROIs, structured as 
                                        session x perc (med, lo, high)
        - sign_sess_grped (list)   : significant session indices, 
                                        optionally structured by tail
        - all_diffs   (list)       : differences, structured as 
                                        session x ROI
        - p_vals_grped (list)      : p values for each comparison, 
                                        organized by session pairs (where the 
                                        second session is cycled in the inner 
                                        loop, e.g., 0-1, 0-2, 1-2, including 
                                        empty groups)
        - p_vals_sess_grped (list) : p values for each session
        )

        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    if len(sessions) == 0:
        raise ValueError("At least one session must be passed.") 

    if datatype == "run" and grped_only:
        raise ValueError("'grped_only' can only be set to True for ROI data.")         

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise RuntimeError("There should be the same number of sessions for "
            "each mouse.")
    n_sess = n_sess[0]

    st_len = 2 + (analyspar.stats == "median" and analyspar.error == "std")

    seed = rand_util.seed_all(seed, "cpu", log_seed=False)

    n_mice = len(sessions)
    mouse_diff_st = np.empty([n_mice, n_sess, st_len]) * np.nan
    all_rand = np.empty([n_mice, n_sess, permpar.n_perms]) * np.nan
    all_roi_vals = [[] for _ in range(n_sess)]
    sess_info = []
    for m, m_sess in enumerate(sessions):
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(
            m_sess, analyspar.fluor, add_none=True, incl_roi=(datatype=="roi"), 
            rem_bad=analyspar.rem_bad)
        for s, sess in enumerate(m_sess):
            if sess is None:
                continue
        
            n_perms = None if grped_only else permpar.n_perms
            mouse_diff_st[m, s], sess_rand, add_rois = split_diff_by_sess(
                    sess, analyspar, stimpar, n_perms=n_perms, 
                    datatype=datatype, split=split, baseline=baseline)
            
            if not grped_only: # otherwise, it is None
                all_rand[m, s] = sess_rand
            if datatype == "roi":
                all_roi_vals[s].append(add_rois)

        sess_info.append(m_sess_info)


    returns = []
    if not grped_only:
        [all_diff_st, CI_vals, sign_sess, p_vals_sess] = get_mouse_stats(
            mouse_diff_st, all_rand, analyspar, permpar)

        returns = [mouse_diff_st.tolist(), all_diff_st, CI_vals, sign_sess, 
            p_vals_sess]

    if datatype == "roi":
        grped_returns = get_grped_roi_stats(all_roi_vals, analyspar, permpar)    
    
        returns = returns + grped_returns

    return returns + [sess_info]
    

#############################################
def split_diff_by_linpla(sessions, analyspar, stimpar, permpar, datatype="roi", 
                         split="by_exp", baseline=0.0, seed=None, 
                         parallel=False):
    """
    split_diff_by_linpla(sessions, analyspar, stimpar, permpar)
    
    Returns dictionary containing difference between sequence data splits, as 
    well as lists of session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters  
        
    Optional args:
        - datatype (str)         : type of data (e.g., "roi", "run")
                                   default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  "stim_onset": grayscreen vs stimulus onset
                                  "stim_offset": stimulus offset vs grayscreen
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0        
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - diff_info (dict)       : dictionary with difference info
            ["all_diff_stats"] (list)  : difference stats across mice, 
                                         structured as plane/line x session 
                                                                  x stats
            ["mouse_diff_stats"] (list): difference statistics across ROIs or 
                                         seqs, structured as 
                                             plane/line x mouse x session 
                                                        x stats
            ["CI_vals"] (list)         : CIs values, structured as
                                             plane/line x session 
                                                        x perc (med, lo, high)
            ["sign_sess"] (list)       : significant session indices, 
                                         structured as plane/line (x tails)
            ["p_vals_sess"] (list)     : p values for each session, structured 
                                         as plane/line x session
            ["linpla_ord"] (list)      : order list of planes/lines
        if datatype == "roi": (
            ["all_diff_st_grped"] (list): difference stats across ROIs (grouped 
                                          across mice), structured as 
                                          plane/line x session x stats
            ["CI_vals_grped"] (list)    : CIs values across ROIs, structured as 
                                          plane/line x session 
                                                     x perc (med, lo, high)
            ["lin_p_vals"] (list)       : p-values for each line comparison, 
                                          structured as line x session (np.nan 
                                          for sessions  missing in either plane)
            ["p_vals_grped"] (list)     : p values for each comparison, 
                                          organized by session pairs (where the 
                                          second session is cycled in the inner 
                                          loop, e.g., 0-1, 0-2, 1-2, including 
                                          empty groups)
            ["sign_sess_grped"] (list)  : significant session indices, 
                                          structured as plane/line (x tails)
            )

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
        - permpar (PermPar)       : permutation parameters named tuple updated 
                                    with multiple comparisons, if applicable          
    """

    if (split in ["unexp_lock", "exp_lock", "stim_onset", "stim_offset"] and 
        stimpar.pre != stimpar.post):
        raise ValueError("For unexp_lock, exp_lock, stim_onset or stim_offset "
            "analysis, stimpar.pre and stimpar.post must be the same.")
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    permpar = set_multcomp(permpar, sessions=linpla_sess)
    
    # optionally runs in parallel
    args_list = [analyspar, stimpar, permpar, datatype, split, baseline, 
        False, seed]
    outs = gen_util.parallel_wrap(split_diff_by_sesses, linpla_sess, args_list, 
        parallel=parallel, zip_output=True)

    diff_info = dict()
    if datatype == "roi":
        [mouse_diff_st, all_diff_st, all_CI_vals, all_sign_sess, 
            all_p_vals_sess, all_diff_st_grped, all_CI_vals_grped, 
            all_sign_sess_grped, all_diffs_grped, all_p_vals_grped,  
            _, sess_info] = outs
        diff_info["all_diff_stats_grped"] = all_diff_st_grped
        diff_info["CI_vals_grped"]    = all_CI_vals_grped
        diff_info["sign_sess_grped"]  = all_sign_sess_grped
        diff_info["p_vals_grped"]     = all_p_vals_grped
        
        # compare across planes in a line
        diff_info["lin_p_vals"] = comp_vals_acr_planes(
            linpla_order, all_diffs_grped, permpar.n_perms, 
            stats=analyspar.stats).tolist()

    elif datatype == "run":
        [mouse_diff_st, all_diff_st, all_CI_vals, 
         all_sign_sess, all_p_vals_sess, sess_info] = outs
    else:
        gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

    diff_info["all_diff_stats"]   = all_diff_st
    diff_info["mouse_diff_stats"] = mouse_diff_st
    diff_info["CI_vals"]          = all_CI_vals
    diff_info["sign_sess"]        = all_sign_sess
    diff_info["linpla_ord"]       = linpla_order
    diff_info["p_vals_sess"]      = all_p_vals_sess

    return diff_info, sess_info, permpar


#############################################
def run_unexp_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar, datatype="roi", 
                       parallel=False):
    """
    run_unexp_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar)

    Retrieves area values by session x unexp val and plots statistics across 
    ROIs of difference between expected and unexpected responses.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "s")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.visflow_dir, stimpar.visflow_size, stimpar.gabk,
        "print")
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected - expected locked "
        f"{datastr} responses \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})


    diff_info, sess_info, permpar = split_diff_by_linpla(
        sessions, analyspar, stimpar, permpar, datatype, split="by_exp", 
        baseline=basepar.baseline, seed=seed, parallel=parallel)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar": analyspar._asdict(),
            "sesspar"  : sesspar._asdict(),
            "stimpar"  : stimpar._asdict(),
            "basepar"  : basepar._asdict(),
            "permpar"  : permpar._asdict(),
            "extrapar" : extrapar,
            "sess_info": sess_info,
            "diff_info": diff_info
            }

    fulldir, savename = acr_sess_plots.plot_unexp_area_diff(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")

      
#############################################
def run_lock_area_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar, datatype="roi", 
                       parallel=False):
    """
    run_lock_area_diff(sessions, analysis, analyspar, sesspar, stimpar, 
                       basepar, permpar, figpar)

    Retrieves area values by session x unexp val, locked to unexpected onset and 
    plots statistics across ROIs of difference between expected and unexpected
    responses.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "l")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.visflow_dir, stimpar.visflow_size, stimpar.gabk,
        "print")
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected - expected {datastr} "
        f"responses \n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    if stimpar.pre != stimpar.post:
        warnings.warn(f"stimpar.post {stimpar.post} will be used for "
              "pre and post.", category=RuntimeWarning, stacklevel=1)
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, "pre", stimpar.post)
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, _ = split_by_linpla(sessions, rem_empty=True)
    permpar = set_multcomp(permpar, sessions=linpla_sess)

    all_diff_info = []
    all_sess_info = []
    for lock in ["unexp_lock", "exp_lock"]:
        diff_info, sess_info, permpar = split_diff_by_linpla(
            sessions, analyspar, stimpar, permpar, datatype, split=lock, 
            baseline=basepar.baseline, seed=seed, parallel=parallel)
        all_diff_info.append(diff_info)
        all_sess_info.append(sess_info)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar" : analyspar._asdict(),
            "sesspar"   : sesspar._asdict(),
            "stimpar"   : stimpar._asdict(),
            "permpar"   : permpar._asdict(),
            "basepar"   : basepar._asdict(),
            "extrapar"  : extrapar,
            "sess_info" : all_sess_info,
            "diff_info" : all_diff_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_area_diff(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def run_stim_grayscr_diff(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                          basepar, permpar, figpar, datatype="roi", 
                          parallel=False):
    """
    run_stim_grayscr_diff(sessions, analysis, analyspar, sesspar, stimpar, 
                          basepar, permpar, figpar)

    Retrieves area values by session, locked to stimulus onset/offset and plots 
    statistics across ROIs of difference between splits.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "a")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    if stimpar.stimtype != "both":
        raise ValueError("Stimulus grayscreen analysis must include both "
            "stimulus types.")

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.visflow_dir, stimpar.visflow_size, stimpar.gabk,
        "print")
    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting {datastr} stimulus onset and offset "
        f"responses \n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    if stimpar.pre != stimpar.post:
        warnings.warn(f"stimpar.post {stimpar.post} will be used for "
              "pre and post.", category=RuntimeWarning, stacklevel=1)
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, "pre", stimpar.post)

    all_diff_info = []
    all_sess_info = []
    for split in ["stim_onset", "stim_offset"]:
        diff_info, sess_info, permpar = split_diff_by_linpla(
            sessions, analyspar, stimpar, permpar, datatype, split=split, 
            baseline=basepar.baseline, seed=seed, parallel=parallel)
        all_diff_info.append(diff_info)
        all_sess_info.append(sess_info)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar": analyspar._asdict(),
            "sesspar"  : sesspar._asdict(),
            "stimpar"  : stimpar._asdict(),
            "basepar"  : basepar._asdict(),
            "permpar"  : permpar._asdict(),
            "extrapar" : extrapar,
            "sess_info": all_sess_info,
            "diff_info": all_diff_info
            }

    fulldir, savename = acr_sess_plots.plot_stim_grayscr_diff(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def split_traces_by_sesses(sessions, analyspar, stimpar, datatype="roi", 
                           split="by_exp", baseline=0.0):
    """
    split_traces_by_sesses(sessions, analyspar, stimpar)

    Returns dictionary containing sequence data split, as well as lists of 
    session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
    
    Returns:
        - traces_acr_mice (list)  : mean traces across ROIs and sequences, 
                                    structured as
                                      mouse x session x split1, 2 x frame
        - sess_info (nested list) : nested list of dictionaries for each 
                                    mouse containing information from each 
                                    session, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
        if datatype == "roi": (
        - traces_acr_rois (list)  : mean traces across sequences, structured as
                                      session x mouse x split1, 2 [x ROI] 
                                      x frame
        )
                                    split1, 2 ordered in time, i.e.
                                    if split in 
                                        ["by_exp", "unexp_lock", "prog_unexp"]:
                                        split1, 2: exp, unexp
                                    elif split in ["exp_lock", "prog_exp"]:
                                        split1, 2: unexp, exp
                                    elif split is "stim_onset":
                                        split1, 2: grayscr, stim
                                    elif split is "stim_offset:
                                        split1, 2: stim, grayscr
    """

    if len(sessions) == 0:
        raise ValueError("At least one session must be passed.") 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise RuntimeError("There should be the same number of sessions for "
            "each mouse.")
    n_sess = n_sess[0]

    sess_info = []
    traces_acr_mice = []
    traces_acr_rois = [[] for _ in range(n_sess)]
    for m_sess in sessions:
        # get the segments
        m_sess_info = sess_gen_util.get_sess_info(m_sess, analyspar.fluor, 
            add_none=True, incl_roi=(datatype=="roi"), 
            rem_bad=analyspar.rem_bad)
        nan_idx = []
        mouse_traces = []
        for s, sess in enumerate(m_sess):
            if sess is None:
                nan_idx.append(s)
                continue
            # split [x ROI] x seq x frames
            data_arr = split_data_by_sess(sess, analyspar, stimpar, 
                datatype=datatype, split=split, baseline=baseline)
            # get mean/median across seqs
            data_arr = [math_util.mean_med(sub_arr, stats=analyspar.stats, 
                axis=-2) for sub_arr in data_arr]
            if datatype == "roi": # get mean/median across ROIs
                mean_med = [math_util.mean_med(sub_arr, stats=analyspar.stats, 
                    axis=0) for sub_arr in data_arr]
                traces_acr_rois[s].append(data_arr)
            elif datatype == "run":
                mean_med = data_arr
            mouse_traces.append(mean_med)
        sess_info.append(m_sess_info)
        mouse_traces = np.asarray(mouse_traces)

        for i in nan_idx: # add NaNs back in for appropriate sessions
            mouse_traces = np.insert(mouse_traces, i, np.nan, axis=0)
        traces_acr_mice.append(mouse_traces)

    if datatype == "roi":
        return traces_acr_mice, sess_info, traces_acr_rois
    else:
        return traces_acr_mice, sess_info


#############################################
def split_trace_stats_by_sesses(sessions, analyspar, stimpar, datatype="roi", 
                                split="by_exp", baseline=0.0):
    """
    split_trace_stats_by_sesses(sessions, analyspar, stimpar)
    
    Returns dictionary containing split sequence data, as well as lists of 
    session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0

    Returns:       
        - trace_st (list)         : trace statistics, structured as
                                    session x split1, 2 x frame x stats
        if datatype == "roi": (
        - trace_st_acr_rois (list): trace statistics across ROIs, grouped 
                                    across mice, structured as
                                    session x split1, 2 x frame x stats
        )
                                    split1, 2 ordered in time, i.e.
                                    if split in ["by_exp", "unexp_lock", "prog_unexp"]:
                                        split1, 2: exp, unexp
                                    elif split in ["exp_lock", "prog_exp"]:
                                        split1, 2: unexp, exp
                                    elif split is "stim_onset":
                                        split1, 2: grayscr, stim
                                    elif split is "stim_offset:
                                        split1, 2: stim, grayscr

        - xran (list)             : second values for each frame
        - sess_info (nested list) : nested list of dictionaries for each 
                                    mouse containing information from each 
                                    session, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    returns = split_traces_by_sesses(
        sessions, analyspar, stimpar, datatype, split, baseline)
    
    traces_acr_mice = returns[0]
    sess_info = returns[1]

    # stats x sess x split x frames
    trace_st = math_util.get_stats(np.asarray(traces_acr_mice), 
        stats=analyspar.stats, error=analyspar.error, axes=0, nanpol="omit")
    n_fr = trace_st.shape[-1]
    trace_st = np.transpose(trace_st, [1, 2, 3, 0]).tolist()

    pre = stimpar.pre
    if split in ["unexp_lock", "exp_lock", "stim_onset", "stim_offset"]:
        pre = 0
    xran = np.linspace(-pre, stimpar.post, n_fr).tolist()

    # stats across ROIs (grouped across mice)
    if datatype == "roi":
        traces_acr_rois = returns[2]
        nan_idx = []
        trace_st_acr_rois = []
        for s, sess_traces in enumerate(traces_acr_rois):
            if len(sess_traces) == 0:
                nan_idx.append(s)
                continue
            # split x ROIs x frames
            sess_traces = np.concatenate(sess_traces, axis=1)
            # split x frames x stats
            sess_sts = np.transpose(math_util.get_stats(sess_traces, 
                stats=analyspar.stats, error=analyspar.error, 
                axes=1, nanpol="omit"), [1, 2, 0])
            trace_st_acr_rois.append(sess_sts.tolist())
        for i in nan_idx:
            trace_st_acr_rois = np.insert(trace_st_acr_rois, i, np.nan, 
                axis=0).tolist()

        return trace_st, trace_st_acr_rois, xran, sess_info
    
    else:
        return trace_st, xran, sess_info


#############################################
def split_traces_by_linpla(sessions, analyspar, stimpar, datatype="roi", 
                           split="by_exp", baseline=0.0, parallel=False):
    """
    split_traces_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing split sequence data, as well as lists of 
    session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - split (str)           : how to split data, either 
                                  "by_exp": all exp vs all unexp, or
                                  "unexp_lock": unexp, vs preceeding exp, or
                                  "exp_lock": exp, vs preceeding unexp
                                  default: "by_exp"
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - trace_info (dict)      : dictionary with difference info
            ["linpla_ord"] (list) : order list of planes/lines            
            ["trace_stats"] (list): trace statistics, structured as
                                    plane/line x session x split1, 2 x frame 
                                               x stats
            ["xran"] (list)       : second values for each frame
            if datatype == "roi": 
            ["trace_st_grped"] (list): trace statistics across ROIs, 
                                       grouped across mice, structured 
                                       as session x split1, 2 x frame x stats

                                    split1, 2 ordered in time, i.e.
                                    if split in ["by_exp", "unexp_lock", 
                                        "prog_unexp"]:
                                        split1, 2: exp, unexp
                                    elif split in ["exp_lock", "prog_exp"]:
                                        split1, 2: unexp, exp
                                    elif split is "stim_onset":
                                        split1, 2: grayscr, stim
                                    elif split is "stim_offset:
                                        split1, 2: stim, grayscr

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    if (split in ["unexp_lock", "exp_lock", "stim_onset", "stim_offset"] and 
        stimpar.pre != stimpar.post):
        raise ValueError("For unexp_lock, exp_lock, stim_onset or stim_offset "
            "analysis, stimpar.pre and stimpar.post must be the same.")

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    # optionally runs in parallel
    args_list = [analyspar, stimpar, datatype, split, baseline]
    outs = gen_util.parallel_wrap(split_trace_stats_by_sesses, linpla_sess, 
        args_list, parallel=parallel, zip_output=True)  
    
    if datatype == "run":
        [trace_stats, xrans, sess_info] = outs    
    elif datatype == "roi":
        [trace_stats, trace_stats_acr_rois, xrans, sess_info] = outs    
    else:
        gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

    trace_info = {"xran"       : xrans[0],
                  "trace_stats": trace_stats,
                  "linpla_ord" : linpla_order
                  }

    if datatype == "roi":
        trace_info["trace_stats_grped"] = trace_stats_acr_rois

    return trace_info, sess_info


#############################################
def run_unexp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar, datatype="roi", parallel=False):
    """
    run_unexp_traces(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    figpar)

    Retrieves area values by session x unexp val and plots statistics across 
    ROIs of difference between expected and unexpected events.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "t")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected v expected {datastr} "
        f"traces  \n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    trace_info, sess_info = split_traces_by_linpla(
        sessions, analyspar, stimpar, datatype, split="by_exp", 
        baseline=basepar.baseline, parallel=parallel)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                }

    info = {"analyspar" : analyspar._asdict(),
            "sesspar"   : sesspar._asdict(),
            "stimpar"   : stimpar._asdict(),
            "basepar"   : basepar._asdict(),
            "extrapar"  : extrapar,
            "sess_info" : sess_info,
            "trace_info": trace_info
            }

    fulldir, savename = acr_sess_plots.plot_unexp_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")

      
#############################################
def run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar, datatype="roi", parallel=False):
    """
    run_lock_traces(sessions, analysis, analyspar, sesspar, stimpar, 
                    basepar, figpar)

    Retrieves area values by session x unexp val, locked to unexpected seq., 
    then expected seq. onset and plots statistics across ROIs of difference 
    between both.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "r")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info("Analysing and plotting unexpected v expected locked "
        f"{datastr} traces \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})

    if stimpar.pre != stimpar.post:
        warnings.warn(f"stimpar.post {stimpar.post} will be used for "
            "pre and post.", category=RuntimeWarning, stacklevel=1)
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, "pre", stimpar.post)

    if stimpar.stimtype == "gabors":
        n_cycles = stimpar.post/1.5
        if int(n_cycles) != n_cycles:
            raise RuntimeError("Locked analysis should not be used for "
                "incomplete gabor cycles, as different parts of the cycle "
                "are then compared.")

    all_sess_info = []
    all_trace_info = []
    for lock in ["unexp_lock", "exp_lock"]:
        trace_info, sess_info = split_traces_by_linpla(
            sessions, analyspar, stimpar, datatype, split=lock, 
            baseline=basepar.baseline, parallel=parallel)
        all_sess_info.append(sess_info)
        all_trace_info.append(trace_info)
        

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                }

    info = {"analyspar" : analyspar._asdict(),
            "sesspar"   : sesspar._asdict(),
            "stimpar"   : stimpar._asdict(),
            "basepar"   : basepar._asdict(),
            "extrapar"  : extrapar,
            "sess_info" : all_sess_info,
            "trace_info": all_trace_info
            }

    fulldir, savename = acr_sess_plots.plot_lock_traces(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")


#############################################
def run_stim_grayscr(sessions, analysis, analyspar, sesspar, stimpar, 
                     basepar, figpar, datatype="roi", parallel=False):
    """
    run_stim_grayscr(sessions, analysis, analyspar, sesspar, stimpar, 
                     basepar, figpar)

    Retrieves area values by session x split, locked to stimulus onset, then 
    offset and plots statistics across ROIs of difference between 
    stimulus and grayscreen periods.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "b")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    if stimpar.stimtype != "both":
        raise ValueError("Stimulus grayscreen analysis must include both "
            "stimulus types.")

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.visflow_dir, stimpar.visflow_size, stimpar.gabk,
        "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info("Analysing and plotting stimulus onset and offset locked "
        f"{datastr} traces \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})

    if stimpar.pre != stimpar.post:
        warnings.warn(f"stimpar.post {stimpar.post} will be used for "
            "pre and post.", category=RuntimeWarning, stacklevel=1)
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, "pre", stimpar.post)

    all_sess_info = []
    all_trace_info = []
    for lock in ["stim_onset", "stim_offset"]:
        trace_info, sess_info = split_traces_by_linpla(
            sessions, analyspar, stimpar, datatype, split=lock, 
            baseline=basepar.baseline, parallel=parallel)
        all_sess_info.append(sess_info)
        all_trace_info.append(trace_info)
        

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                }

    info = {"analyspar" : analyspar._asdict(),
            "sesspar"   : sesspar._asdict(),
            "stimpar"   : stimpar._asdict(),
            "basepar"   : basepar._asdict(),
            "extrapar"  : extrapar,
            "sess_info" : all_sess_info,
            "trace_info": all_trace_info
            }

    fulldir, savename = acr_sess_plots.plot_stim_grayscr_traces(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")


#############################################
def prog_by_sesses(sessions, analyspar, stimpar, datatype="roi", 
                   unexp="prog_unexp", position=0, baseline=0.0, seq_st=False, 
                   diff=False):
    """
    prog_by_sesses(sessions, analyspar, stimpar)

    Returns differences between unexpected sequences and the preceeding 
    expected sequence (or v.v.), as well as lists of session information 
    dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - unexp (str)            : how to split unexpected vs exp data, either 
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  default: "prog_unexp"
        - position (int)        : unexpected or expected position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - seq_st (bool)         : if True, stats are taken across sequences
                                  default: False

    Returns:
        - mouse_seq_st (list)    : difference statistics across ROIs for each 
                                   sequence or across sequences, structured as 
                                       mouse x session [x unexps] [x seqs] 
                                           x stats
        - all_seq_st (list)      : difference statistics across mice for each 
                                   sequence, structured as 
                                       session [x unexps] [x seqs] x stats
        if datatype == "roi": (
        - grped_seq_st (list): difference statistics across ROIs grouped by 
                                session for each sequence, or across 
                                sequences, structured as 
                                    session [x unexps] [x seqs] x stats
        )
        - sess_info (nested list): nested list of dictionaries for each 
                                   mouse containing information from each 
                                   session, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    if len(sessions) == 0:
        raise ValueError("At least one session must be passed.") 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise RuntimeError("There should be the same number of sessions for "
            "each mouse.")
    n_sess = n_sess[0]

    st_len = 2 + (analyspar.stats == "median" and analyspar.error == "std")

    nanpol = "omit"
    if analyspar.rem_bad:
        nanpol = None

    n_mice = len(sessions)
    upper_bound = 1000

    # n_mice x n_sess x unexps x n_seq x stats
    mouse_seq_st = np.empty([n_mice, n_sess, 2, upper_bound, st_len]) * np.nan
    if diff:
        mouse_seq_st = mouse_seq_st[:, :, 0]

    all_roi_vals = [[] for _ in range(n_sess)]
    sess_info = []
    cut_seq = upper_bound
    for m, m_sess in enumerate(sessions):
        m_sess_info = sess_gen_util.get_sess_info(
            m_sess, analyspar.fluor, add_none=True, incl_roi=(datatype=="roi"), 
            rem_bad=analyspar.rem_bad)
        for s, sess in enumerate(m_sess):
            if sess is None:
                continue
            # unexps x (ROIs x) sequences
            try:
                data_arr = prog_by_sess(sess, analyspar, stimpar, 
                    datatype=datatype, unexp=unexp, position=position, 
                    baseline=baseline)
                if diff:
                    data_arr = data_arr[1] - data_arr[0]
            except Exception as e:
                # catch error if the position value is too high and no segments 
                # meet the criteria
                if "No segments" in str(e):
                    continue
                else:
                    raise(e)
            n_seqs = data_arr.shape[-1]
            if n_seqs > mouse_seq_st.shape[-2]:
                raise NotImplementedError("Implementation problem: "
                    f"'upper_bound' set too low at {upper_bound}, as some "
                    f"sessions have {n_seqs} sequences.")
            cut_seq = np.min([cut_seq, n_seqs])
            upper_bound = None # allows a later check

            # set target slice (mouse, session, unexps)
            targ_slice = (slice(m, m + 1), slice(s, s + 1), slice(None))
            if diff:
                targ_slice = targ_slice[:-1]
            if datatype == "roi":
                all_roi_vals[s].append(data_arr)
                mouse_seq_st[targ_slice + (slice(0, n_seqs), )] = \
                    np.moveaxis(math_util.get_stats(
                        data_arr, stats=analyspar.stats, error=analyspar.error, 
                        axes=-2, nanpol=nanpol), 0, -1)
            else:
                mouse_seq_st[targ_slice + (slice(0, n_seqs), 0)] = data_arr
        sess_info.append(m_sess_info)

    # cut down to number of sequences
    mouse_seq_st = mouse_seq_st[..., :cut_seq, :]

    if seq_st:
        mouse_seq_st = np.moveaxis(math_util.get_stats(
            mouse_seq_st[..., 0], stats=analyspar.stats, 
            error=analyspar.error, axes=-1, nanpol="omit"), 0, -1)

    all_seq_st = np.moveaxis(math_util.get_stats(mouse_seq_st[..., 0], 
        stats=analyspar.stats, error=analyspar.error, axes=0, 
        nanpol="omit"), 0, -1).tolist()

    if datatype == "roi":
        # session x mouse [x unexps] x [ROI x seqs] -> 
        # session [x unexps] [x seqs] x stats
        grped_seq_st = []
        for sess_vals in all_roi_vals:
            if len(sess_vals) == 0:
                cut_seq = cut_seq if upper_bound is None else 1
                targ_shape = [cut_seq, st_len]
                if seq_st:
                    targ_shape = [st_len]
                if not diff:
                    targ_shape = [2] + targ_shape
                grped_seq_st.append((np.empty(targ_shape) * np.nan).tolist())
            else:
                sess_vals = np.concatenate(
                    [data[..., :cut_seq] for data in sess_vals], axis=-2) 
                targ_ax = -2
                if seq_st:
                    targ_ax = [-2, -1]

                grped_seq_st.append(np.moveaxis(math_util.get_stats(
                    sess_vals, stats=analyspar.stats, error=analyspar.error, 
                    axes=targ_ax, nanpol=nanpol), 0, -1).tolist())

        return mouse_seq_st.tolist(), all_seq_st, grped_seq_st, sess_info

    else:
        return mouse_seq_st.tolist(), all_seq_st, sess_info
        

#############################################
def prog_by_linpla(sessions, analyspar, stimpar, datatype="roi", 
                   unexp="prog_unexp", position=0, baseline=0.0, 
                   parallel=False):
    """
    prog_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing difference between an unexpected sequence 
    and the preceeding expected sequence (or v.v.), as well as lists of session 
    information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters  
        
    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - unexp (str)            : how to split unexpected vs exp data, either 
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  default: "prog_unexp"
        - position (int)        : unexpected or expected position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - prog_info (dict)       : dictionary with unexpected progression info
            ["prog_stats"] (list)           : unexpected progression stats 
                                              across mice, structured as 
                                                  plane/line x session x unexps 
                                                  x seq x stats
            ["prog_diff_stats"] (list)      : unexpected difference progression 
                                              stats across mice, structured as 
                                                  plane/line x session x seq 
                                                  x stats
            ["mouse_prog_stats"] (list)     : unexpected progression stats 
                                              across ROIs, structured as 
                                                 plane/line x mouse x session x
                                                 unexps x seq x stats
            ["mouse_prog_diff_stats"] (list): unexpected difference progression 
                                              stats across ROIs, structured as 
                                                 plane/line x mouse x session x
                                                 seq x stats

            ["linpla_ord"] (list)      : order list of planes/lines
        if datatype == "roi": (
            ["prog_stats_grped"] (list)     : unexpected progression stats 
                                              across ROIs (grouped across mice), 
                                              structured as 
                                                  plane/line x session x unexps 
                                                  x seqs x stats
            ["prog_diff_stats_grped"] (list): unexpected difference progression 
                                              stats across ROIs (grouped across 
                                              mice), structured as 
                                                  plane/line x session 
                                                  x seqs x stats
            )
        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    prog_info = dict()
    for diff in [False, True]:

        # optionally runs in parallel
        args_list = [analyspar, stimpar, datatype, unexp, position, baseline]
        args_dict = {"diff": diff}
        outs = gen_util.parallel_wrap(prog_by_sesses, linpla_sess, args_list, 
            args_dict, parallel=parallel, zip_output=True)

        diff_str = "_diff" if diff else ""

        if datatype == "roi":
            [mouse_seq_st, all_seq_st, grped_seq_st, sess_info] = outs
            prog_info[f"prog{diff_str}_stats_grped"] = grped_seq_st
            
        elif datatype == "run":
            [mouse_seq_st, all_seq_st, sess_info] = outs
        else:
            gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

        prog_info[f"prog{diff_str}_stats"]       = all_seq_st
        prog_info[f"mouse_prog{diff_str}_stats"] = mouse_seq_st
        prog_info["linpla_ord"]                  = linpla_order

    return prog_info, sess_info


#############################################
def position_by_linpla(sessions, analyspar, stimpar, datatype="roi", 
                       unexp="prog_unexp", position=0, baseline=0.0, 
                       parallel=False):
    """
    position_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing stats for difference between an unexpected 
    sequence and the preceeding expected sequence (or v.v.), across sessions, 
    as well as session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - unexp (str)            : how to split unexpected vs exp data, either 
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  default: "prog_unexp"
        - position (int)        : unexpected or expected position to retrieve
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - pos_info (dict)       : dictionary with unexpected position info
            ["pos_stats"] (list)      : unexpected position stats across 
                                        mice, structured as 
                                           plane/line x session x stats
            ["mouse_pos_stats"] (list): unexpected position stats across 
                                        sequences, structured as 
                                            plane/line x mouse x session 
                                                x  stats
            ["linpla_ord"] (list)      : order list of planes/lines
        if datatype == "roi": (
            ["pos_stats_grped"] (list): unexpected position stats across 
                                        sequences (ROIs grouped across mice), 
                                        structured as 
                                            plane/line x session x stats
            )

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    # optionally runs in parallel
    args_list = [analyspar, stimpar, datatype, unexp, position, baseline]
    args_dict = {"seq_st": True, "diff": True}
    outs = gen_util.parallel_wrap(prog_by_sesses, linpla_sess, args_list, 
        args_dict, parallel=parallel, zip_output=True)

    pos_info = dict()
    if datatype == "roi":
        [mouse_seq_st, all_seq_st, grped_seq_st, sess_info] = outs
        pos_info["pos_stats_grped"] = grped_seq_st
        
    elif datatype == "run":
        [mouse_seq_st, all_seq_st, sess_info] = outs
    else:
        gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

    pos_info["pos_stats"]        = all_seq_st
    pos_info["mouse_pos_stats"]  = mouse_seq_st
    pos_info["linpla_ord"]       = linpla_order

    return pos_info, sess_info


#############################################
def stim_idx_by_linpla(sessions, analyspar, stimpar, permpar, datatype="roi", 
                       feature="by_exp", op="d-prime", position=0, 
                       baseline=0.0, common_oris=False, seed=None, 
                       parallel=False):
    """
    stim_idx_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing stimulus indices for ROIs or running, across 
    sessions, as well as session information dictionaries.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters  
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp/tails do not apply to identifiying 
                                  significant ROI indices)

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split data, either 
                                  "by_exp"  : unexpected vs expected sequences
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  "dir": left vs right (Visflow)
                                  default: "by_exp"
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - common_oris (bool)    : if True, only Gabor stimulus orientations 
                                  common to D and U frames are included 
                                  ("by_exp" feature only)
                                  default: False
        - seed (int)            : seed value to use. (-1 treated as None)
                                  default: None
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - idx_info (dict)   : dictionary with feature index info
            ["item_idxs"] (list) : feature index bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ["item_percs"] (list): feature percentile bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ["rand_idxs"] (list) : random feature index bin counts for each 
                                   ROI or running value, grouped across mice, 
                                   structured as 
                                       plane/line x session x bin
            ["perc_pos"] (list)  : for each session number, percent ROIs with 
                                   positive indices, grouped across mice, 
                                   structured as 
                                       plane/line x session 
            ["bin_edges"] (list) : data edges for indices, structured as 
                                       plane/line x session x [min, max]
            ["linpla_ord"] (list): order list of planes/lines

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    # optionally runs in parallel
    args_list = [analyspar, stimpar, permpar.n_perms, permpar.p_val, datatype, 
        feature, op, position, baseline, common_oris, seed]

    [lp_item_idxs, lp_item_percs, lp_rand_idxs, lp_perc_pos, 
     lp_bin_edges, sess_info] = \
        gen_util.parallel_wrap(
            stim_idx_by_sesses, linpla_sess, args_list, parallel=parallel, 
            zip_output=True, pass_parallel=True)

    idx_info = dict()

    idx_info["item_idxs"]  = lp_item_idxs
    idx_info["item_percs"] = lp_item_percs
    idx_info["rand_idxs"]  = lp_rand_idxs
    idx_info["perc_pos"]   = lp_perc_pos
    idx_info["bin_edges"]  = lp_bin_edges
    idx_info["linpla_ord"] = linpla_order

    return idx_info, sess_info


#############################################
def run_unexp_idx(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                 basepar, permpar, idxpar, figpar, datatype="roi", 
                 parallel=False):
    """
    run_unexp_idx(sessions, analysis, analyspar, sesspar, stimpar, 
                 basepar, permpar, idxpar, figpar)

    Retrieves unexpected event indices for each item (ROI or 1 running item) 
    and plots indices within a session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "i")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp/tails do not apply to identifiying 
                                  significant ROI indices)
        - idxpar (IdxPar)      : named tuple containing index parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")

    if not analyspar.scale:
        warnings.warn("Setting analyspar.scale to True.", 
            category=RuntimeWarning, stacklevel=1)
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, "scale", True)

    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected event indices for "
        f"{datastr} \n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    # check if unexpected feature is accepted
    gabor_features = ["by_exp", "unexp_lock", "prog_unexp"]
    visflow_features = ["by_exp", "unexp_lock"]
    for stimtype, features in zip(
        ["gabors", "visflow"], [gabor_features, visflow_features]):
        if stimpar.stimtype == stimtype and idxpar.feature not in features:
            gen_util.accepted_values_error(
                "idxpar.feature", idxpar.feature, features)

    unexp_idx_info, sess_info = stim_idx_by_linpla(
        sessions, analyspar, stimpar, permpar, datatype, 
        feature=idxpar.feature, op=idxpar.op, position=idxpar.position, 
        baseline=basepar.baseline, seed=seed, parallel=parallel)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar"     : analyspar._asdict(),
            "sesspar"       : sesspar._asdict(),
            "stimpar"       : stimpar._asdict(),
            "basepar"       : basepar._asdict(),
            "permpar"       : permpar._asdict(),
            "idxpar"        : idxpar._asdict(),
            "extrapar"      : extrapar,
            "sess_info"     : sess_info,
            "unexp_idx_info": unexp_idx_info
            }

    fulldir, savename = acr_sess_plots.plot_unexp_idx(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def run_unexp_idx_common_oris(sessions, analysis, seed, analyspar, sesspar, 
                             stimpar, basepar, permpar, idxpar, figpar, 
                             datatype="roi", parallel=False):
    """
    run_unexp_idx_common_oris(sessions, analysis, seed, analyspar, sesspar, 
                             stimpar, permpar, idxpar, figpar)

    Retrieves unexpected event indices for each item (ROI or 1 running item) 
    for Gabors with orientations common expected and unexpected events, and 
    plots indices within a session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "m")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp/tails do not apply to identifiying 
                                  significant ROI indices)
        - idxpar (IdxPar)      : named tuple containing index parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    if stimpar.stimtype != "gabors":
        warnings.warn("Unexpected index analysis with common orientations "
            "can only be run on Gabors.", category=UserWarning, stacklevel=1)
        return

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")

    if not analyspar.scale:
        warnings.warn("Setting analyspar.scale to True.", 
            category=RuntimeWarning, stacklevel=1)
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, "scale", True)

    gab_ori = sess_gen_util.gab_oris_common_U(stimpar.gab_ori)
    stimpar = sess_ntuple_util.get_modif_ntuple(stimpar, "gab_ori", gab_ori)

    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected event indices for common "
        f"orientations {datastr} \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})

    # check if unexpected feature is accepted
    gabor_features = ["by_exp", "unexp_lock", "prog_unexp"]
    if idxpar.feature not in gabor_features:
        gen_util.accepted_values_error(
            "idxpar.feature", idxpar.feature, gabor_features)

    unexp_idx_info, sess_info = stim_idx_by_linpla(
        sessions, analyspar, stimpar, permpar, datatype, 
        feature=idxpar.feature, op=idxpar.op, position=idxpar.position, 
        baseline=basepar.baseline, common_oris=True, seed=seed, 
        parallel=parallel)


    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar"    : analyspar._asdict(),
            "sesspar"      : sesspar._asdict(),
            "stimpar"      : stimpar._asdict(),
            "basepar"      : basepar._asdict(),
            "permpar"      : permpar._asdict(),
            "idxpar"       : idxpar._asdict(),
            "extrapar"     : extrapar,
            "sess_info"    : sess_info,
            "unexp_idx_info": unexp_idx_info
            }

    fulldir, savename = acr_sess_plots.plot_unexp_idx_common_oris(
        figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def run_direction_idx(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                      basepar, permpar, idxpar, figpar, datatype="roi", 
                      parallel=False):
    """
    run_direction_idx(sessions, analysis, analyspar, sesspar, stimpar, 
                      basepar, permpar, figpar)

    Retrieves direction indices for each item (ROI or 1 running item) and plots 
    progression within a session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "d")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp/tails do not apply to identifiying 
                                  significant ROI indices)
        - idxpar (IdxPar)      : named tuple containing index parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    if stimpar.stimtype != "visflow":
        warnings.warn("Direction index analysis can only be run on Visflow.", 
            category=UserWarning, stacklevel=1)
        return

    if stimpar.visflow_dir != "both":
        warnings.warn("Setting stimpar.visflow_dir to 'both'.", 
            category=RuntimeWarning, stacklevel=1)
        stimpar = sess_ntuple_util.get_modif_ntuple(
            stimpar, "visflow_dir", "both"
            )

    if idxpar.feature != "bydir":
        warnings.warn("Setting idxpar.feature to 'bydir'.", 
            category=RuntimeWarning, stacklevel=1)
        idxpar = sess_ntuple_util.get_modif_ntuple(idxpar, "feature", "bydir")

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")

    if not analyspar.scale:
        warnings.warn("Setting analyspar.scale to True.", 
            category=RuntimeWarning, stacklevel=1)
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, "scale", True)

    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting direction indices for {datastr} "
        f"\n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    diridx_info = []
    sess_info = []
    for direc in ["dir_exp", "dir_unexp"]:
        diridx_info_sub, sess_info_sub = stim_idx_by_linpla(
            sessions, analyspar, stimpar, permpar, datatype, feature=direc, 
            op=idxpar.op, position=idxpar.position, baseline=basepar.baseline, 
            seed=seed, parallel=parallel)
        diridx_info.append(diridx_info_sub)
        sess_info.append(sess_info_sub)
    
    if sess_info[0] != sess_info[1]:
        raise NotImplementedError("Did not expect different 'sess_info'.")
    else:
        sess_info = sess_info[0]

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar"  : analyspar._asdict(),
            "sesspar"    : sesspar._asdict(),
            "stimpar"    : stimpar._asdict(),
            "basepar"    : basepar._asdict(),
            "permpar"    : permpar._asdict(),
            "idxpar"     : idxpar._asdict(),
            "extrapar"   : extrapar,
            "sess_info"  : sess_info,
            "diridx_info": diridx_info
            }

    fulldir, savename = acr_sess_plots.plot_direction_idx(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def stimpar_split_idx_acr_sesses(sessions, analyspar, stimpar, datatype="roi", 
                                 feature="by_exp", position=0, op="d-prime", 
                                 n_perms=1000, baseline=0.0, parallel=False):
    """
    stimpar_split_idx_acr_sesses(sessions, analyspar, stimpar)
    
    Returns item (ROIs or running) indices for difference between stimulus 
    features (e.g., unexpected v expected, visual flow direction), as well as 
    their percentiles based on random permutations for each item, grouped 
    across mice for the session number.

    Separate indices are calculated for different orientations (Gabors) or 
    different directions (Visflow).

    Required args:
        - sessions (list)      : Session objects for each mouse
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split stimuli, e.g.,
                                  "by_exp": all exp vs all unexp, or
                                  "prog_unexp": first unexp, vs prec. exp, or
                                  "prog_exp": first exp, vs prec. unexp, or
                                  "dir_exp": left v right direction (exp.),
                                  "dir_unexp": left v right direction (unexp.),
                                  "dir": left v right direction
                                  default: "by_exp"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0 
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, sessions are analysed in parallel 
                                  (not implemented)
                                  default: False

    Returns:
        - all_item_idxs (list) : item (ROIs or running) split indices 
                                 grouped across mice, structured as 
                                    stimulus parameter x item
    """

    if stimpar.stimtype == "gabors":
        stim_vals = stimpar.gab_ori
        if stimpar.gab_ori in ["any", "all"] or not isinstance(stimpar.gab_ori, list):
            raise ValueError("Must provide stimpar.gab_ori as a list.")
        stim_key = "gab_ori"
    elif stimpar.stimtype == "visflow":
        if (stimpar.visflow_dir not in ["all", "any", "both"] and 
            len(stimpar.visflow_dir) < 2):
            raise ValueError("Must include at least 2 visual flow directions "
                "for colormap index analysis.")
        stim_vals = ["left", "right"]
        stim_key = "visflow_dir"

    all_item_idxs = [[] for _ in range(len(stim_vals))]
    for sess in sessions:
        if sess is None:
            continue
        n_rois = None
        fill_nans = []
        # run through each value
        for v, val in enumerate(stim_vals):
            stimpar_use = sess_ntuple_util.get_modif_ntuple(
                stimpar, stim_key, val)
            try:
                item_idxs = stim_idx_by_sess(
                    sess, analyspar, stimpar_use, n_perms=n_perms, 
                    datatype=datatype, 
                    feature=feature, position=position, op=op, 
                    baseline=baseline, run_random=False)
                n_rois = len(item_idxs)
                all_item_idxs[v].extend(item_idxs.tolist())
            except Exception as e:
                if stim_key == "visflow_dir" and "No segments" in str(e):
                    fill_nans.append(v)
                    continue
                else:
                    raise e

        # if some stim parameters had no segments,
        if len(fill_nans):
            if n_rois is None:
                raise NotImplementedError("Did not expect no stimulus values "
                    "to have segments.")
            empty_nans = (np.empty(n_rois) * np.nan).tolist()
            for v in fill_nans:
                all_item_idxs[v].extend(empty_nans)

    return all_item_idxs


#############################################
def stimpar_split_idx_by_sesses(sessions, analyspar, stimpar, datatype="roi", 
                                feature="by_exp", position=0, op="d-prime", 
                                n_perms=1000, baseline=0.0, parallel=False):
    """
    stimpar_split_idx_by_sesses(sessions, analyspar, stimpar)
    
    Returns item (ROIs or running) indices for difference between 
    stimulus features (e.g., unexpected v expected, visual flow direction), 
    grouped across mice for each session number.

    Separate indices are calculated for different orientations (Gabors) or 
    different directions (Visflow).

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split stimuli, e.g.,
                                  "by_exp": all exp vs all unexp, or
                                  "prog_unexp": first unexp, vs prec. exp, or
                                  "prog_exp": first exp, vs prec. unexp, or
                                  "dir_exp": left v right direction (exp.),
                                  "dir_unexp": left v right direction (unexp.),
                                  "dir": left v right direction
                                  default: "by_exp"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0 
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, sessions are analysed in parallel 
                                  default: False
    Returns:
        - all_item_idxs (list) : for each session number, item (ROIs or running) 
                                 indices per stimulus parameter, grouped across 
                                 mice
        - sess_info (list)     : nested list of dictionaries for each 
                                 session number containing information from 
                                 each mouse, with None for missing sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """

    if len(sessions) == 0:
        raise ValueError("At least one session must be passed.") 

    n_sess = list(set([len(m_sess) for m_sess in sessions]))
    if len(n_sess) != 1:
        raise RuntimeError("There should be the same number of sessions for "
            "each mouse.")
    sessions_zipped = zip(*sessions)

    all_item_idxs = []
    sess_info = []
    for sesses in sessions_zipped:
        sesses = list(sesses)
        all_item_idxs.append(stimpar_split_idx_acr_sesses(
            sesses, analyspar, stimpar, datatype=datatype, feature=feature, 
            position=position, op=op, n_perms=n_perms, baseline=baseline, 
            parallel=parallel)
            )
            
        sess_info.append(sess_gen_util.get_sess_info(
            sesses, analyspar.fluor, add_none=True, incl_roi=(datatype=="roi"), 
            rem_bad=analyspar.rem_bad))
        
    return all_item_idxs, sess_info


#############################################
def stimpar_split_idx_by_linpla(sessions, analyspar, stimpar, datatype="roi", 
                                feature="by_exp", position=0, op="d-prime", 
                                n_perms=1000, baseline=0.0, parallel=False):
    """
    stimpar_split_idx_by_linpla(sessions, analyspar, stimpar)
    
    Returns dictionary containing indices for ROIs or running across sessions, 
    as well as session information dictionaries.

    Separate indices are calculated for different orientations (Gabors) or 
    different directions (Visflow).

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters  

    Optional args:
        - datatype (str)        : type of data (e.g., "roi", "run")
                                  default: "roi"
        - feature (str)         : how to split data, either 
                                  "by_exp"  : unexpected vs expected sequences
                                  "prog_unexp": unexp, vs preceeding exp, 
                                      but not locked (e.g., U, vs prev D) 
                                      (i.e., pre not necessarily equal to post)
                                  "prog_exp": exp, vs preceeding unexp, 
                                      but not locked (e.g., D, vs prev U)
                                      (i.e., pre not necessarily equal to post)
                                  "dir": left vs right (Visflow)
                                  default: "by_exp"
        - position (int)        : unexpected or expected position to retrieve 
                                  if unexp is "prog_unexp" or "prog_exp"
                                  default: 0
        - op (str)              : operation to use in measuring indices 
                                  ("diff", "rel_diff", "d-prime")
                                  default: "d-prime"
        - n_perms (int)         : number of permutations for CI estimation
                                  default: 1000
        - baseline (bool or num): if not False, number of second to use for 
                                  baseline
                                  default: 0.0
        - parallel (bool)       : if True, some of the analysis is run in 
                                  parallel across CPU cores 
                                  default: False

    Returns:
        - idx_info (dict)   : dictionary with feature index info
            ["item_idxs"] (list) : feature indices for each ROI or running 
                                   value, grouped across mice, structured as 
                                       plane/line x session x stimpar
            ["linpla_ord"] (list): order list of planes/lines

        - sess_info (nested list): nested list of dictionaries for each 
                                   line/plane x mouse containing information 
                                   from each session, with None for missing 
                                   sessions
            ["mouse_ns"] (list)   : mouse numbers
            ["sess_ns"] (list)    : session numbers  
            ["lines"] (list)      : mouse lines
            ["planes"] (list)     : imaging planes
            ["nrois"] (list)      : number of ROIs in session
    """
    
    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_order = split_by_linpla(sessions, rem_empty=True)

    # optionally runs in parallel
    args_list = [
        analyspar, stimpar, datatype, feature, position, op, n_perms, baseline
        ]

    [lp_item_idxs, sess_info] = \
        gen_util.parallel_wrap(
            stimpar_split_idx_by_sesses, linpla_sess, args_list, 
            parallel=parallel, zip_output=True, pass_parallel=True)

    idx_info = dict()

    idx_info["item_idxs"]  = lp_item_idxs
    idx_info["linpla_ord"] = linpla_order

    return idx_info, sess_info


#############################################
def run_unexp_idx_cm(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                     idxpar, permpar, figpar, datatype="roi", parallel=False):
    """
    run_unexp_idx_cm(sessions, analysis, analyspar, sesspar, stimpar, basepar, 
                    idxpar, permpar, figpar)

    Retrieves unexpected event indices for each item (ROI or 1 running item) 
    and stimulus parameter and plots within a session, as well as across 
    sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "c")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - basepar (BasePar)    : named tuple containing baseline parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp/tails do not apply to identifiying 
                                  significant ROI indices)
        - idxpar (IdxPar)      : named tuple containing index parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")

    if not analyspar.scale:
        warnings.warn("Setting analyspar.scale to True.", 
            category=RuntimeWarning, stacklevel=1)
        analyspar = sess_ntuple_util.get_modif_ntuple(analyspar, "scale", True)

    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting unexpected event indices by stimulus "
        f"parameter for {datastr} \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})

    # check if unexpected feature is accepted
    gabor_features = ["by_exp", "unexp_lock", "prog_unexp"]
    visflow_features = ["by_exp", "unexp_lock"]
    for stimtype, features in zip(
        ["gabors", "visflow"], [gabor_features, visflow_features]):
        if stimpar.stimtype == stimtype and idxpar.feature not in features:
            gen_util.accepted_values_error(
                "idxpar.feature", idxpar.feature, features)

    stimpar_use = stimpar
    if stimpar.stimtype == "gabors":
        if "unexp" in idxpar.feature: 
            if stimpar.gabfr in [3, 4]:
                gab_oris = sess_gen_util.filter_gab_oris("U", stimpar.gab_ori)
            else:
                gab_oris = sess_gen_util.filter_gab_oris("D", stimpar.gab_ori)

            stimpar = sess_ntuple_util.get_modif_ntuple(
                stimpar, "gab_ori", gab_oris
                )

        # for unexp segments, orientation will be adjusted
        if idxpar.feature == "by_exp":
            gab_oris = sess_gen_util.filter_gab_oris("D", stimpar.gab_ori)

            stimpar_use = sess_ntuple_util.get_modif_ntuple(
                stimpar, "gab_ori", gab_oris
                )

    unexp_idx_info, sess_info = stimpar_split_idx_by_linpla(
        sessions, analyspar, stimpar_use, datatype=datatype, 
        n_perms=permpar.n_perms, feature=idxpar.feature, op=idxpar.op, 
        position=idxpar.position, baseline=basepar.baseline, parallel=parallel)

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                }

    info = {"analyspar"     : analyspar._asdict(),
            "sesspar"       : sesspar._asdict(),
            "stimpar"       : stimpar._asdict(),
            "basepar"       : basepar._asdict(),
            "idxpar"        : idxpar._asdict(),
            "permpar"       : permpar._asdict(),
            "extrapar"      : extrapar,
            "sess_info"     : sess_info,
            "unexp_idx_info": unexp_idx_info
            }

    fulldir, savename = acr_sess_plots.plot_unexp_idx_cms(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")
    


#############################################
def run_prog(sessions, analysis, analyspar, sesspar, stimpar, figpar, 
             datatype="roi", parallel=False):
    """
    run_prog(sessions, analysis, analyspar, sesspar, stimpar, figpar)

    Retrieves difference between unexpected response, and the 
    preceeding expected response (and v.v.), and plots progression within a 
    session, as well as across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "g")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting progression of unexpected v "
        f"previous expected {datastr} response (and v.v.) "
        f"\n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

  
    max_n_unexp = 4
    positions = np.arange(max_n_unexp)

    for position in positions:
        all_sess_info = []
        all_prog_info = []
        logger.info(f"For position {position}.", extra={"spacing": "\n"})      
        for prog in ["prog_unexp", "prog_exp"]:
            prog_info, sess_info = prog_by_linpla(
                sessions, analyspar, stimpar, datatype, unexp=prog, 
                baseline=0, position=position, parallel=parallel)
            all_prog_info.append(prog_info)
            all_sess_info.append(sess_info)

        extrapar = {"analysis": analysis,
                    "datatype": datatype,
                    "position": sess_str_util.get_position_name(position),
                    }

        info = {"analyspar"  : analyspar._asdict(),
                "sesspar"    : sesspar._asdict(),
                "stimpar"    : stimpar._asdict(),
                "extrapar"   : extrapar,
                "sess_info"  : all_sess_info,
                "prog_info"  : all_prog_info
                }

        fulldir, savename = acr_sess_plots.plot_prog(figpar=figpar, **info)
        file_util.saveinfo(info, savename, fulldir, "json")
    

#############################################
def run_position(sessions, analysis, analyspar, sesspar, stimpar, figpar, 
                 datatype="roi", parallel=False):
    """
    run_position(sessions, analysis, analyspar, sesspar, stimpar, figpar)

    Retrieves difference response to unexpected in each position (first, 
    second, third), and the preceeding expected response (and v.v.), and plots 
    progression across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "o")
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    sessstr_pr = sess_str_util.sess_par_str(
        sesspar.sess_n, stimpar.stimtype, sesspar.plane, stimpar.visflow_dir, 
        stimpar.visflow_size, stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
       
    datastr = sess_str_util.datatype_par_str(datatype)

    logger.info(f"Analysing and plotting progression of unexpected v "
        f"previous expected {datastr} response (and v.v.) across sessions "
        f"\n({sessstr_pr}{dendstr_pr}).", extra={"spacing": "\n"})

    max_n_unexp = 4
    positions = np.arange(max_n_unexp)

    for position in positions:
        all_sess_info = []
        all_pos_info = []
        logger.info(f"For position {position}.", extra={"spacing": "\n"})
        for prog in ["prog_unexp", "prog_exp"]:
            pos_info, sess_info = position_by_linpla(
                sessions, analyspar, stimpar, datatype, unexp=prog, 
                baseline=0, position=position, parallel=parallel)
            all_pos_info.append(pos_info)
            all_sess_info.append(sess_info)

        extrapar = {"analysis": analysis,
                    "datatype": datatype,
                    "position": sess_str_util.get_position_name(position),
                    }

        info = {"analyspar"  : analyspar._asdict(),
                "sesspar"    : sesspar._asdict(),
                "stimpar"    : stimpar._asdict(),
                "extrapar"   : extrapar,
                "sess_info"  : all_sess_info,
                "pos_info"   : all_pos_info
                }

        fulldir, savename = acr_sess_plots.plot_position(figpar=figpar, **info)
        file_util.saveinfo(info, savename, fulldir, "json")


#############################################
def get_rise_latency(data_arr, xran, method="ttest", p_val_thr=0.005, 
                     stats="mean", rel_std=0.5, pad_win=0):
    """
    get_rise_latency(data_arr, xran)

    Returns rise latency values for each item (e.g., ROI) to reach threshold.

    Required args:
        - data_arr (3D array): data array, structured as 
                               item (e.g., ROI) x sequences x frames
                               (padded if pad_win != 0)
        - xran (list)        : latency values in seconds for each frame 
                               (padded)

    Optional args:
        - method (str)     : method to use to determine latency
                             "ttest": first point higher than start point that 
                                      reaches p-value
                             "ratio": first point higher than start point by a 
                                      certain ratio of standard deviations 
                             default: "ttest"
        - p_val_thr (float): threshold p value to use for t-test method
                             default: 0.005 
        - stats (str)      : statistic to take for starting point for ratio 
                             method
                             default: "mean"
        - rel_std (float)  : threshold standard deviation ratio to use to for 
                             ratio method
                             default: 0.5
        - pad_win (int)    : number of padding frames used to smooth and 
                             augment data
                             default: 0

    Returns:
        - lat_vals (list): latency values (for all items that reach threshold 
                           for a peak latency to be determined)
        - roi_ns (list)  : numbers of the ROIs that reached threshold
    """


    if len(data_arr.shape) != 3:
        raise ValueError("Data array must be 3 dimensions.")
    
    fr_axis = len(data_arr.shape) - 1

    if pad_win:
        if pad_win%2 == 0:
            raise NotImplementedError("Using an even padding window may "
                "not work as expected as it is not symmetrical around "
                "each point.") 
        # stack shifted array to combine 3 points for each point estimate
        pad_fr = pad_win//2
        n_fr = data_arr.shape[-1]
        data_stack = [data_arr[gen_util.slice_idx(
            fr_axis, slice(i, n_fr + i - pad_win + 1))] for i in range(pad_win)
            ]
        # concatenate sequences to augment and smooth data
        data_arr = np.concatenate(data_stack, axis=fr_axis - 1)
        xran = xran[pad_fr : -pad_fr]

    if method == "ratio":
        # stats (x ROI) x frame
        data_st = math_util.get_stats(
            data_arr, stats=stats, error="std", axes=1, nanpol="omit")
        all_med = data_st[0]
        med_st = data_st[0][gen_util.slice_idx(fr_axis - 1, 0)].reshape(-1, 1)
        stat_dev = data_st[1][gen_util.slice_idx(fr_axis - 1, 0)].reshape(-1, 1)
        rat = (all_med - med_st)/stat_dev # rel strength of signal                    
    
    roi_ns = []
    lat_vals = []
    for r in range(len(data_arr)):
        if method == "ratio":
            r_idx = np.argmax(rat[r] > rel_std)
        elif method == "ttest":
            r_idx = 0 
            for p in range(1, data_arr.shape[-1]):
                t_stat, p_val = scist.ttest_rel(
                    data_arr[r, :, 0], data_arr[r, :, p], axis=None)
                if t_stat > 0 and p_val < p_val_thr:
                    r_idx = p
                    break
        else:
            gen_util.accepted_values_error(
                "method", method, ["ratio", "ttest"]
                )
        if r_idx == 0: # if never peaks, skips to nan
            continue
        else:
            roi_ns.append(r)
            lat_vals.append(xran[r_idx])

    return lat_vals, roi_ns


#############################################
def get_sess_latencies(sess, analyspar, stimpar, latpar, permpar=None, 
                       seed=None, datatype="roi"):
    """
    get_sess_latencies(sess, analyspar, stimpar)

    Returns latency values for the session.

    Required args:
        - sess (Session object): session object (can be None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple containing latency parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.unexp_resp is True.
                             (multcomp does not apply to identifiying 
                              significant ROI unexpected responses)
                             default: None
        - seed (int)       : seed value to use. (-1 treated as None)
                             default: None
        - datatype (str)   : type of data (e.g., "roi", "run")
                             default: "roi"

    Returns:
        - lat_vals (list)   : latency values for the session or None if no 
                              session (None if no session)
        - roi_ns (list)     : numbers of the ROIs that reached threshold
        if latpar.unexp_resp: (
        - signif_rois (list): numbers of the ROIs that showed significant 
                              unexpected responses
        )
    """


    if datatype == "run" and latpar.unexp_resp:
        raise ValueError(
            "cannot set latpar.unexp_resp to True if running data."
            )

    if sess is None:
        return [None, []] + [[]] * latpar.unexp_resp
    stim = sess.get_stim(stimpar.stimtype)
    remconsec = (stimpar.stimtype == "visflow")
    unexps = [1]
    if latpar.unexp_resp:
        if stimpar.stimtype == "visflow":
            unexps = [1, 1]
            pre_posts = [[1.0, 0], [0, 1.0]]    
        elif stimpar.stimtype == "gabors":
            unexps = [0, 1]
            pre_posts = [[0, 0.45]] * 2
        else:
            gen_util.accepted_values_error("stimpar.stimtype", 
                stimpar.stimtype, ["visflow", "gabors"])

    all_segs = [stim.get_segs_by_criteria(gabfr=stimpar.gabfr, 
        gabk=stimpar.gabk, gab_ori=stimpar.gab_ori, 
        visflow_dir=stimpar.visflow_dir, 
        visflow_size=stimpar.visflow_size, unexp=unexp, by="seg", 
        remconsec=remconsec) 
        for unexp in unexps]

    if analyspar.rem_bad:
        nanpol = None
    else:
        nanpol = "omit"

    if datatype == "roi":
        if stim.sess.only_tracked_rois != analyspar.tracked:
            raise RuntimeError(
                "stim.sess.only_tracked_rois should match analyspar.tracked."
                )
        twop_frs = [
            stim.get_fr_by_seg(segs, start=True, fr_type="twop"
            )["start_frame_twop"] for segs in all_segs
            ]
        # array: ROI x sequences x frames
        # pad with one frame before and after
        pad_win = 3
        pad = (pad_win//2, pad_win//2)
        # get data for last unexp value,  xran is padded
        roi_data_df = stim.get_roi_data(
            twop_frs[-1], stimpar.pre, stimpar.post, fluor=analyspar.fluor, 
            rem_bad=analyspar.rem_bad, scale=analyspar.scale, pad=pad
            ) #, smooth=win_pad)
        xran = roi_data_df.index.unique("time_values").to_numpy() 
        data_arr = gen_util.reshape_df_data(roi_data_df, squeeze_cols=True)  
        # identify unexpected event responsive ROIs
        if latpar.unexp_resp:
            if permpar is None:
                raise ValueError("Must pass a 'permpar' if latpar.unexp_resp.")
            elif permpar.tails != "hi":
                raise ValueError("permpar.tails must be 'hi'.")
            seed = rand_util.seed_all(seed, "cpu", log_seed=False)
            # full_arr: unexp x ROI x sequences
            integ_data = [gen_util.reshape_df_data(stim.get_roi_data(
                twop_fr, pre=pre, post=post, fluor=analyspar.fluor, integ=True,
                rem_bad=analyspar.rem_bad, 
                scale=analyspar.scale)["roi_traces"], squeeze_cols=True)
                for twop_fr, [pre, post] in zip(twop_frs, pre_posts)]   
            signif_rois = signif_grps.get_signif_rois(
                integ_data, permpar, stats=analyspar.stats, op="diff", 
                nanpol=nanpol, log_rois=False)
            data_arr = data_arr[signif_rois]

    elif datatype == "run":
        # array: 1 x sequences x frames
        stim_fr = stim.get_fr_by_seg(
            all_segs[-1], start=True, fr_type="stim")["start_frame_stim"]
        run_data_df = stim.get_run_data(
            stim_fr, stimpar.pre, stimpar.post, rem_bad=analyspar.rem_bad, 
            scale=analyspar.scale)["run_velocity"]
        # padding not implemented for running data
        pad_win = 0
        xran = run_data_df.index.unique("time_values").to_numpy()
        data_arr = np.expand_dims(
            gen_util.reshape_df_data(run_data_df, squeeze_cols=True), 0)
    else:
        gen_util.accepted_values_error("datatype", datatype, ["run", "roi"])

    lat_vals, roi_ns = get_rise_latency(
        data_arr, xran, method=latpar.method, p_val_thr=latpar.p_val_thr, 
        stats=analyspar.stats, rel_std=latpar.rel_std, pad_win=pad_win)
    if latpar.unexp_resp:
        # retrieve original roi_ns based on signif_rois
        roi_ns = list(np.asarray(signif_rois)[roi_ns])
        return lat_vals, roi_ns, signif_rois
    else:
        return lat_vals, roi_ns


#############################################
def run_unexp_latency(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                      latpar, figpar, permpar=None, datatype="roi", 
                      parallel=False):
    """
    run_unexp_latency(sessions, analysis, analyspar, sesspar, stimpar, 
                     latpar, figpar)

    Retrieves area values by session x unexp val, locked to unexpected onset 
    and plots statistics across ROIs of difference between expected and 
    unexpected.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "u")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - permpar (PermPar)    : named tuple containing permutation parameters
                                 (multcomp does not apply to identifiying 
                                  significant ROI unexpected responses)
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.unexp_resp is True.
                             default: None
        - datatype (str)   : type of data (e.g., "roi", "run")
                             default: "roi"
        - parallel (bool)  : if True, some of the analysis is run in parallel 
                             across CPU cores 
                             default: False
    """
    
    if latpar.unexp_resp:
        if datatype == "run":
            warnings.warn("Setting latpar.unexp_resp to False as datatype is "
                "run.", category=RuntimeWarning, stacklevel=1)
            latpar = sess_ntuple_util.get_modif_ntuple(
                latpar, "unexp_resp", False)
        elif permpar is None:
            raise ValueError("Must pass a 'permpar' if latpar.unexp_resp.")
        elif permpar.tails != "hi":
            warnings.warn("Setting permpar.tails to 'hi'.", 
                category=RuntimeWarning, stacklevel=1)
            permpar = sess_ntuple_util.get_modif_ntuple(permpar, "tails", "hi")

    sessstr_pr = sess_str_util.sess_par_str(sesspar.sess_n, stimpar.stimtype, 
        sesspar.plane, stimpar.visflow_dir, stimpar.visflow_size, 
        stimpar.gabk, "print")
    dendstr_pr = sess_str_util.dend_par_str(
        analyspar.dend, sesspar.plane, datatype, "print")
    
    datastr = sess_str_util.datatype_par_str(datatype)

    stat_len = 2 + (analyspar.error == "std")
    
    logger.info(f"Analysing and plotting unexpected event response latency "
        f"for {datastr} traces  \n({sessstr_pr}{dendstr_pr}).", 
        extra={"spacing": "\n"})

    seed = rand_util.seed_all(seed, "cpu", log_seed=False)

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)
    permpar = set_multcomp(permpar, sessions=linpla_sess, CIs=False)

    [all_lat_stats, all_lat_vals, 
     all_lat_p_vals, all_lat_vals_flat] = [], [], [], []
    all_sess_info = []

    all_n_sign_rois = []
    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_lat_vals, l_lat_vals_flat, l_sess_info = [], [], []
        l_lat_stats = np.full([stat_len, len(l_sesses)], np.nan)
        l_n_sign_rois = []
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(
                sesses, analyspar.fluor, add_none=True, 
                incl_roi=(datatype=="roi"), rem_bad=analyspar.rem_bad))
            # for each mouse, optionally runs in parallel
            args_list = [analyspar, stimpar, latpar, permpar, seed, datatype]
            sess_vals = gen_util.parallel_wrap(
                get_sess_latencies, sesses, args_list, parallel=parallel, 
                zip_output=False)

            # extract info from sess_vals
            sess_lat_vals = [vals[0] for vals in sess_vals]
            if latpar.unexp_resp:
                sess_n_sign_rois = [len(vals[2]) for vals in sess_vals]

            # all values across mice for the session
            lat_vals_flat = np.asarray(
                [val for sub_vals in sess_lat_vals if sub_vals is not None
                for val in sub_vals])
            l_lat_stats[:, s] = math_util.get_stats(
                lat_vals_flat, analyspar.stats, analyspar.error, nanpol="omit")
            l_lat_vals_flat.append(lat_vals_flat)
            l_lat_vals.append(sess_lat_vals)
            if latpar.unexp_resp:
                l_n_sign_rois.append(sess_n_sign_rois)

        p_vals = rand_util.comp_vals_acr_groups(
            l_lat_vals_flat, n_perms=permpar.n_perms, 
            stats=analyspar.stats).tolist()

        all_sess_info.append(l_sess_info)
        all_lat_stats.append(l_lat_stats.tolist())
        all_lat_vals_flat.append(l_lat_vals_flat)
        all_lat_vals.append(l_lat_vals)
        all_lat_p_vals.append(p_vals)
        if latpar.unexp_resp:
            all_n_sign_rois.append(l_n_sign_rois)


    # compare across planes in a line
    lin_p_vals = comp_vals_acr_planes(
        linpla_ord, all_lat_vals_flat, permpar.n_perms, stats=analyspar.stats)
    
    lat_data = {"linpla_ord"   : linpla_ord,
                "lat_stats"    : all_lat_stats,
                "lat_vals"     : all_lat_vals,
                "lat_p_vals"   : all_lat_p_vals,
                "lin_p_vals"   : lin_p_vals.tolist(),
                }

    if latpar.unexp_resp:
        lat_data["n_sign_rois"] = all_n_sign_rois

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                "seed"    : seed,
                }

    info = {"analyspar": analyspar._asdict(),
            "sesspar"  : sesspar._asdict(),
            "stimpar"  : stimpar._asdict(),
            "latpar"   : latpar._asdict(),
            "permpar"  : permpar._asdict(),
            "extrapar" : extrapar,
            "sess_info": all_sess_info,
            "lat_data" : lat_data
            }

    fulldir, savename = acr_sess_plots.plot_unexp_latency(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")


#############################################
def run_resp_prop(sessions, analysis, seed, analyspar, sesspar, stimpar, 
                  latpar, figpar, permpar=None, parallel=False):
    """
    run_resp_prop(sessions, analysis, analyspar, sesspar, stimpar, latpar,
                  figpar)

    Retrieves proportion of ROIs that show a response to unexpected within a 
    limited latency for both stimuli and plots statistics across sessions.
        
    Saves results and parameters relevant to analysis in a dictionary.

    Required args:
        - sessions (list)      : nested list of Session objects (mouse x sess)
        - analysis (str)       : analysis type (e.g., "p")
        - seed (int)           : seed value to use. (-1 treated as None)
        - analyspar (AnalysPar): named tuple containing analysis parameters
        - sesspar (SessPar)    : named tuple containing session parameters
        - stimpar (StimPar)    : named tuple containing stimulus parameters
        - latpar (LatPar)      : named tuple of latency parameters
        - figpar (dict)        : dictionary containing figure parameters
    
    Optional args:
        - permpar (PermPar): named tuple containing permutation parameters. 
                             Required only if latpar.unexp_resp is True.
                             (multcomp does not apply to identifiying 
                              significant ROI unexpected responses)
                             default: None
        - datatype (str) : type of data (e.g., "roi", "run")
                           default: "roi"
        - parallel (bool): if True, some of the analysis is run in parallel 
                           across CPU cores 
                           default: False
    """

    datatype = "roi"

    if latpar.unexp_resp:
        if permpar is None:
            raise ValueError("Must pass a 'permpar' if latpar.unexp_resp.")
        elif permpar.tails != "hi":
            warnings.warn("Setting permpar.tails to 'hi'.", 
                category=RuntimeWarning, stacklevel=1)
            permpar = sess_ntuple_util.get_modif_ntuple(permpar, "tails", "hi")

    dendstr_pr = sess_str_util.dend_par_str(analyspar.dend, sesspar.plane, 
        "roi", "print")

    logger.info(
        "Analysing and plotting proportion of unexpected event responsive ROIs"
        f"{dendstr_pr}.", extra={"spacing": "\n"})

    if stimpar.stimtype != "both":
        raise ValueError("stimpar.stimtype must be 'both' for this analysis.")
    stimtypes  = ["gabors", "gabors", "visflow"]
    gabfrs     = [3, 1, "none"]
    comb_names = ["gabfrs", "unexps"]
    combs      = [[0, 1] , [0, 2]]

    # get sessions organized by lin/pla x mouse x session
    linpla_sess, linpla_ord = split_by_linpla(sessions, rem_empty=True)

    all_sess_info = []
    all_prop_stats = []
    all_n_sign_rois = []
    for l_sesses in linpla_sess:
        # switch to sess x mouse
        l_sesses = [list(vals) for vals in zip(*l_sesses)]
        l_sess_info = []
        l_prop_stats = []
        l_n_sign_rois = []
        for s, sesses in enumerate(l_sesses): # across sessions
            l_sess_info.append(sess_gen_util.get_sess_info(sesses, 
                analyspar.fluor, add_none=True, incl_roi=(datatype=="roi"), 
                rem_bad=analyspar.rem_bad))
            # keep only sessions with both stimuli
            sesses = sess_gen_util.check_both_stimuli(sesses)
            nrois = [sess.get_nrois(analyspar.rem_bad, analyspar.fluor) 
                for sess in sesses]
            # sesses x [stims x nrois]
            resp_arrs = [np.full([len(stimtypes), nroi], 0) for nroi in nrois]         
            for s, (stimtype, gabfr) in enumerate(zip(stimtypes, gabfrs)):
                stimpar_spec = sess_ntuple_util.get_modif_ntuple(
                    stimpar, ["stimtype", "gabfr"], [stimtype, gabfr])
                # for each mouse, optionally runs in parallel
                args_list = [analyspar, stimpar_spec, latpar, permpar, seed, 
                    datatype]
                sess_vals = gen_util.parallel_wrap(
                    get_sess_latencies, sesses, args_list, parallel=parallel, 
                    zip_output=False)

                # extract info from sess_vals
                sess_roi_ns = [vals[1] for vals in sess_vals]
                if latpar.unexp_resp:
                    sess_n_sign_rois = [len(vals[2]) for vals in sess_vals]    

                for r, roi_ns in enumerate(sess_roi_ns):
                    if len(roi_ns) > 0:
                        resp_arrs[r][s, np.asarray(roi_ns)] = 1

            resp_prop_stats = []
            for comb in combs:
                comb_props = []
                for nroi, resp_arr in zip(nrois, resp_arrs):
                    if nroi == 0:
                        comb_props.append(np.nan)
                        continue
                    resp_same = resp_arr[comb[0]] == resp_arr[comb[1]]
                    comb_props.append(sum(resp_same)/float(nroi))
                resp_prop_me = math_util.mean_med(
                    comb_props, stats=analyspar.stats, nanpol="omit")
                resp_prop_de = math_util.error_stat(
                    comb_props, stats=analyspar.stats, error=analyspar.error, 
                    nanpol="omit")
                resp_prop_stats.append([resp_prop_me, resp_prop_de])
            l_prop_stats.append(resp_prop_stats)
            if latpar.unexp_resp:
                l_n_sign_rois.append(sess_n_sign_rois)
        all_prop_stats.append(l_prop_stats)
        all_sess_info.append(l_sess_info)
        if latpar.unexp_resp:
            all_n_sign_rois.append(l_n_sign_rois)

    prop_data = {"linpla_ord": linpla_ord,
                 "prop_stats": all_prop_stats,
                 "comb_names": comb_names
                }

    if latpar.unexp_resp:
        prop_data["n_sign_rois"] = all_n_sign_rois

    extrapar = {"analysis": analysis,
                "datatype": datatype,
                }

    info = {"analyspar" : analyspar._asdict(),
            "sesspar"   : sesspar._asdict(),
            "stimpar"   : stimpar._asdict(),
            "latpar"    : latpar._asdict(),
            "extrapar"  : extrapar,
            "sess_info" : all_sess_info,
            "prop_data" : prop_data
            }

    if latpar.unexp_resp:
        info["permpar"]  = permpar._asdict()
        extrapar["seed"] = seed

    fulldir, savename = acr_sess_plots.plot_resp_prop(figpar=figpar, **info)
    file_util.saveinfo(info, savename, fulldir, "json")

